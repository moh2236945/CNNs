{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Very Deep Convolutional Networks for Large-Scale Image Recognition VGG/BN-VGG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObG0kg/rQjyK1Xypg+qF2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh2236945/CNNs/blob/master/Very_Deep_Convolutional_Networks_for_Large_Scale_Image_Recognition_VGG_BN_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CjcR60mOSyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, input_features, output_features, kernel, padding, stride, conv1_1=False):\n",
        "        super(ConvBlock,self).__init__()\n",
        "        self.input_features = input_features\n",
        "        self.output_features = output_features\n",
        "        self.kernel = kernel\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        self.conv1_1 = conv1_1\n",
        "        if conv1_1:\n",
        "            self.conv = nn.Conv2d(in_channels=input_features, out_channels=output_features, kernel_size=1, padding=padding, stride=stride)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels=input_features,out_channels=output_features, kernel_size= kernel, padding=padding, stride= stride)\n",
        "        self.bNorm= nn.BatchNorm2d(output_features)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        output = self.conv(x)\n",
        "        output = self.bNorm(output)\n",
        "        output = self.relu(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Vgg(nn.Module):\n",
        "    def __init__(self, num_channels, num_classes, depth, conv1_1= False, initialize_weights=True ):\n",
        "        super(Vgg,self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.depth = depth\n",
        "        layers = []\n",
        "        fc_layers = []\n",
        "        base_features = 64\n",
        "        if depth==11:\n",
        "            num_conv_blocks = [0, 0, 1, 1, 2]\n",
        "        elif depth== 13:\n",
        "            num_conv_blocks = [1, 1, 1, 1, 2]\n",
        "        elif depth == 16:\n",
        "            num_conv_blocks = [1, 1, 2, 2, 3]\n",
        "        elif depth==19:\n",
        "            num_conv_blocks = [1, 1, 3, 3, 4]\n",
        "\n",
        "        layers.append(ConvBlock(input_features=num_channels, output_features=base_features, kernel=3, padding=1, stride=1))\n",
        "        for _ in range(num_conv_blocks[0]):\n",
        "            layers.append(ConvBlock(input_features=base_features, output_features=base_features, kernel=3, padding=1,stride=1))\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "        layers.append(ConvBlock(input_features=base_features, output_features=2*base_features, kernel=3, padding=1, stride=1))\n",
        "        for _ in range(num_conv_blocks[1]):\n",
        "            layers.append(ConvBlock(input_features=2*base_features, output_features=2*base_features, kernel=3, padding=1,stride=1))\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "        layers.append(ConvBlock(input_features=2*base_features, output_features=4*base_features, kernel=3, padding=1, stride=1))\n",
        "\n",
        "        if conv1_1:\n",
        "            for _ in range(num_conv_blocks[2]-1):\n",
        "                layers.append(\n",
        "                    ConvBlock(input_features=4 * base_features, output_features=4 * base_features, kernel=3, padding=1,\n",
        "                              stride=1))\n",
        "            layers.append(ConvBlock(input_features=4 * base_features, output_features=4 * base_features, kernel=3,\n",
        "                                    padding=1, stride=1, conv1_1=True))\n",
        "        else:\n",
        "            for _ in range(num_conv_blocks[2]):\n",
        "                layers.append(ConvBlock(input_features=4 * base_features, output_features=4 * base_features, kernel=3, padding=1, stride=1))\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "        layers.append(ConvBlock(input_features=4*base_features, output_features=8*base_features, kernel=3, padding=1, stride=1))\n",
        "\n",
        "        if conv1_1:\n",
        "            for _ in range(num_conv_blocks[3]-1):\n",
        "                layers.append(\n",
        "                    ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3, padding=1,\n",
        "                              stride=1))\n",
        "            layers.append(ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3,\n",
        "                                    padding=1, stride=1, conv1_1=True))\n",
        "        else:\n",
        "            for _ in range(num_conv_blocks[3]):\n",
        "                layers.append(\n",
        "                    ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3, padding=1,\n",
        "                              stride=1))\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "        if conv1_1:\n",
        "            for _ in range(num_conv_blocks[4] - 1):\n",
        "                layers.append(\n",
        "                    ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3, padding=1,\n",
        "                              stride=1))\n",
        "            layers.append(\n",
        "                ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3, padding=1,\n",
        "                          stride=1, conv1_1=True))\n",
        "        else:\n",
        "            for _ in range(num_conv_blocks[4]):\n",
        "                layers.append(\n",
        "                    ConvBlock(input_features=8 * base_features, output_features=8 * base_features, kernel=3, padding=1,\n",
        "                              stride=1))\n",
        "        layers.append(nn.AdaptiveAvgPool2d(2))\n",
        "        fc_layers.extend([nn.Linear(in_features=2*2*(8*base_features), out_features= base_features*base_features),nn.ReLU()])\n",
        "        fc_layers.extend([nn.Linear(in_features=base_features*base_features, out_features= base_features*base_features),nn.ReLU()])\n",
        "        fc_layers.extend([nn.Linear(in_features=base_features*base_features, out_features= self.num_classes)])\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.fc_layers = nn.Sequential(*fc_layers)\n",
        "        if initialize_weights:\n",
        "            self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for  m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out',nonlinearity='relu')\n",
        "                if m.bias is None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        output = self.layers(x)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        # print(output.size())\n",
        "        output = self.fc_layers(output)\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}