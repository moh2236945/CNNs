{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq3NTxn2ohwuuzupFXwLy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15de61d6a37e436292e847af819c8f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_90551952a354480c9902003946294c2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40f46c13ace04614a19fdf72021416e3",
              "IPY_MODEL_43157e911e254aca86bf1a23f21df351"
            ]
          }
        },
        "90551952a354480c9902003946294c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40f46c13ace04614a19fdf72021416e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fd2edff48d7471990f264dae05ff2da",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50761996,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50761996,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e6e3987799a4f9591e4b94b64b99790"
          }
        },
        "43157e911e254aca86bf1a23f21df351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab34792827074e59a10ddd95e05d7baf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48.4M/48.4M [03:40&lt;00:00, 230kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fb37b7568be4db6b3e13a7b5d830662"
          }
        },
        "3fd2edff48d7471990f264dae05ff2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e6e3987799a4f9591e4b94b64b99790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab34792827074e59a10ddd95e05d7baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fb37b7568be4db6b3e13a7b5d830662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cdd8c84f056491c89fe28bbed67280a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32f46c6048dd424d8a3ef9e049431413",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0000af2e396542ba9e0a73ff8c2d9bba",
              "IPY_MODEL_1277a4046650498bbe38a73a7b5577f4"
            ]
          }
        },
        "32f46c6048dd424d8a3ef9e049431413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0000af2e396542ba9e0a73ff8c2d9bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f755fde917e4d689d92b8d2107d6108",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241799809,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241799809,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f88c1cec815b4710afa3ad5aa3a2b04d"
          }
        },
        "1277a4046650498bbe38a73a7b5577f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5380f08b2c7b493daa001fb01848f39f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 231M/231M [11:19&lt;00:00, 356kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f50413bad2ff435e8f5802cdd25442a8"
          }
        },
        "4f755fde917e4d689d92b8d2107d6108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f88c1cec815b4710afa3ad5aa3a2b04d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5380f08b2c7b493daa001fb01848f39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f50413bad2ff435e8f5802cdd25442a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh2236945/CNNs/blob/master/Implementations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYcHQP1lGXM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81fae54d-c4f2-4f34-fd9d-57ddbf06da95"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "__help__=\"you can call VGGnet(kind='vgg16',num_classes=1000,batch_norm=False,pretrained=False) to get a vgg net,\\\n",
        "         you can use __all__ to get the compelete vggnet choose.\\\n",
        "         if you want to use vggxx_bn you should not give the parameter kind='vggxx_bn',\\\n",
        "         you should also give the kind='vggxx_bn' but another parameter batch_norm=True\"\n",
        "\n",
        "__all__=[\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
        "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
        "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
        "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
        "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
        "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    \n",
        "    def __init__(self,features,num_classes=1000,init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features=features\n",
        "        self.classifier=nn.Sequential(\n",
        "            nn.Linear(512*7*7,4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096,num_classes)\n",
        "            )\n",
        "        self.conv1x1=nn.Conv2d(512,num_classes,kernel_size=1,stride=1)\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=self.conv1x1(x)\n",
        "        x=x.view(x.size(0),-1)\n",
        "        #x=self.classifier(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight,1)\n",
        "                nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m,nn.Linear):\n",
        "                nn.init.normal_(m.weight,0,0.01)\n",
        "                nn.init.constant_(m.bias,0)\n",
        "\n",
        "cfg={\n",
        "    'vgg11':[64,'M',128,'M',256,256,'M',512,512,'M',512,512,'M'], #11 weight layers\n",
        "    'vgg13':[64,64,'M',128,128,'M',256,256,'M',512,512,'M',512,512,'M'], #13 weight layers\n",
        "    'vgg16':[64,64,'M',128,128,'M',256,256,256,'M',512,512,512,'M',512,512,512,'M'], #16 weight layers\n",
        "    'vgg19':[64,64,'M',128,128,'M',256,256,256,256,'M',512,512,512,512,'M',512,512,512,512,'M'], #19 weight layers\n",
        "}\n",
        "def make_layers(cfg,batch_norm=False):\n",
        "    layers=[]\n",
        "    in_channels=3\n",
        "    for v in cfg:\n",
        "        if v=='M':\n",
        "            layers+=[nn.MaxPool2d(kernel_size=2,stride=2)]\n",
        "        else:\n",
        "            if batch_norm:\n",
        "                layers+=[nn.Conv2d(in_channels,v,kernel_size=3,padding=1,stride=1,bias=False),\n",
        "                        nn.BatchNorm2d(v),nn.ReLU(True)]\n",
        "            else:\n",
        "                layers+=[nn.Conv2d(in_channels,v,kernel_size=3,padding=1,stride=1),nn.ReLU(True)]\n",
        "            in_channels=v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def VGGnet(kind='vgg16',num_classes=1000,batch_norm=False,pretrained=False,**kwargs):\n",
        "    if pretrained:\n",
        "        kwargs['init_weights']=False\n",
        "        assert num_classes==1000,\\\n",
        "            'pretrained model only on ImageNet which num classes is 1000 but got{}'.format(num_classes)\n",
        "    model=VGG(make_layers(cfg[kind],batch_norm),num_classes,**kwargs)\n",
        "    if pretrained:\n",
        "        name=kind\n",
        "        if batch_norm==True:\n",
        "            name+='_bn'\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls[name]))\n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    a=nn.Conv2d(1,2,kernel_size=1,bias=False)\n",
        "    print(a.bias)\n",
        "    model=VGGnet(kind='vgg16',num_classes=10,batch_norm=True)\n",
        "    print(model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            "  (conv1x1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUWPgkPIIsVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f844c97-1ee7-4d7b-8816-6f57921e48d2"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet264', 'densenet29', 'densenet45',\n",
        "           'densenet85']\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Sequential):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features,\n",
        "                                           bn_size * growth_rate, kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate))\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1, bias=False))\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "    def forward(self, input):\n",
        "        new_features = super(_DenseLayer, self).forward(input)\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return torch.cat([input, new_features], 1)\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.Sequential):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    \"\"\"\n",
        "    growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "    block_config (list of 4 ints) - how many layers in each pooling block\n",
        "    num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "    bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "      (i.e. bn_size * k features in the bottleneck layer)\n",
        "    drop_rate (float) - dropout rate after each dense layer\n",
        "    num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=12, block_config=(6, 12, 24, 16),\n",
        "                 num_init_feature=24, bn_size=4, drop_rate=0, num_classes=1000):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # Firsrt convolution before dense block\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_feature, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_feature)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1))])\n",
        "        )\n",
        "\n",
        "        num_features = num_init_feature\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "        self.features.add_module('relu5', nn.ReLU(inplace=True))\n",
        "        self.features.add_module('avgpool', nn.AdaptiveAvgPool2d((1, 1)))\n",
        "\n",
        "        self.classifier = nn.Conv2d(num_features, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
        "            elif isinstance(m,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight,1)\n",
        "            elif isinstance(m,nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
        "\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        features = self.features(input)\n",
        "        out = self.classifier(features).view(input.size(0), -1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    model = DenseNet(num_init_feature=64, growth_rate=32, block_config=(6, 12, 24, 16), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, **kwargs):\n",
        "    model = DenseNet(num_init_feature=64, growth_rate=32, block_config=(6, 12, 32, 32), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, **kwargs):\n",
        "    model = DenseNet(num_init_feature=64, growth_rate=32, block_config=(6, 12, 48, 32), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet264(pretrained=False, **kwargs):\n",
        "    model = DenseNet(num_init_feature=64, growth_rate=32, block_config=(6, 12, 64, 48), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "class DenseNet_CIFAR10(nn.Module):\n",
        "    \"\"\"\n",
        "    growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "    block_config (list of 4 ints) - how many layers in each pooling block\n",
        "    num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "    bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "      (i.e. bn_size * k features in the bottleneck layer)\n",
        "    drop_rate (float) - dropout rate after each dense layer\n",
        "    num_classes (int) - number of classification classes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=12, block_config=(6, 12, 24, 12),\n",
        "                 num_init_feature=24, bn_size=4, drop_rate=0, num_classes=10):\n",
        "        super(DenseNet_CIFAR10, self).__init__()\n",
        "\n",
        "        # Firsrt convolution before dense block\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_feature, kernel_size=3, stride=1, padding=1, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_feature)),\n",
        "            ('relu0', nn.ReLU(inplace=True))])\n",
        "        )\n",
        "\n",
        "        num_features = num_init_feature\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
        "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "        self.features.add_module('relu5', nn.ReLU(inplace=True))\n",
        "        self.features.add_module('avgpool', nn.AdaptiveAvgPool2d((1, 1)))\n",
        "\n",
        "        self.classifier = nn.Conv2d(num_features, num_classes,kernel_size=1,stride=1)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                ps = list(m.parameters())\n",
        "                if len(ps) == 2:\n",
        "                    nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        features = self.features(input)\n",
        "        out = self.classifier(features).view(input.size(0), -1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def densenet29(pretrained=False, **kwargs):\n",
        "    model = DenseNet_CIFAR10(num_init_feature=48, growth_rate=24, block_config=(6, 6, 6, 6), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet45(pretrained=False, **kwargs):\n",
        "    model = DenseNet_CIFAR10(num_init_feature=48, growth_rate=24, block_config=(10, 10, 10, 10), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet85(pretrained=False, **kwargs):\n",
        "    model = DenseNet_CIFAR10(num_init_feature=48, growth_rate=24, block_config=(20, 20, 20, 20), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net = densenet29().to(\"cuda:0\")\n",
        "    import torchsummary\n",
        "\n",
        "    torchsummary.summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              ReLU-3           [-1, 48, 32, 32]               0\n",
            "       BatchNorm2d-4           [-1, 48, 32, 32]              96\n",
            "              ReLU-5           [-1, 48, 32, 32]               0\n",
            "            Conv2d-6           [-1, 96, 32, 32]           4,608\n",
            "       BatchNorm2d-7           [-1, 96, 32, 32]             192\n",
            "              ReLU-8           [-1, 96, 32, 32]               0\n",
            "            Conv2d-9           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-10           [-1, 72, 32, 32]             144\n",
            "             ReLU-11           [-1, 72, 32, 32]               0\n",
            "           Conv2d-12           [-1, 96, 32, 32]           6,912\n",
            "      BatchNorm2d-13           [-1, 96, 32, 32]             192\n",
            "             ReLU-14           [-1, 96, 32, 32]               0\n",
            "           Conv2d-15           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-16           [-1, 96, 32, 32]             192\n",
            "             ReLU-17           [-1, 96, 32, 32]               0\n",
            "           Conv2d-18           [-1, 96, 32, 32]           9,216\n",
            "      BatchNorm2d-19           [-1, 96, 32, 32]             192\n",
            "             ReLU-20           [-1, 96, 32, 32]               0\n",
            "           Conv2d-21           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-22          [-1, 120, 32, 32]             240\n",
            "             ReLU-23          [-1, 120, 32, 32]               0\n",
            "           Conv2d-24           [-1, 96, 32, 32]          11,520\n",
            "      BatchNorm2d-25           [-1, 96, 32, 32]             192\n",
            "             ReLU-26           [-1, 96, 32, 32]               0\n",
            "           Conv2d-27           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-28          [-1, 144, 32, 32]             288\n",
            "             ReLU-29          [-1, 144, 32, 32]               0\n",
            "           Conv2d-30           [-1, 96, 32, 32]          13,824\n",
            "      BatchNorm2d-31           [-1, 96, 32, 32]             192\n",
            "             ReLU-32           [-1, 96, 32, 32]               0\n",
            "           Conv2d-33           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-34          [-1, 168, 32, 32]             336\n",
            "             ReLU-35          [-1, 168, 32, 32]               0\n",
            "           Conv2d-36           [-1, 96, 32, 32]          16,128\n",
            "      BatchNorm2d-37           [-1, 96, 32, 32]             192\n",
            "             ReLU-38           [-1, 96, 32, 32]               0\n",
            "           Conv2d-39           [-1, 24, 32, 32]          20,736\n",
            "      BatchNorm2d-40          [-1, 192, 32, 32]             384\n",
            "             ReLU-41          [-1, 192, 32, 32]               0\n",
            "           Conv2d-42           [-1, 96, 32, 32]          18,432\n",
            "        AvgPool2d-43           [-1, 96, 16, 16]               0\n",
            "      BatchNorm2d-44           [-1, 96, 16, 16]             192\n",
            "             ReLU-45           [-1, 96, 16, 16]               0\n",
            "           Conv2d-46           [-1, 96, 16, 16]           9,216\n",
            "      BatchNorm2d-47           [-1, 96, 16, 16]             192\n",
            "             ReLU-48           [-1, 96, 16, 16]               0\n",
            "           Conv2d-49           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-50          [-1, 120, 16, 16]             240\n",
            "             ReLU-51          [-1, 120, 16, 16]               0\n",
            "           Conv2d-52           [-1, 96, 16, 16]          11,520\n",
            "      BatchNorm2d-53           [-1, 96, 16, 16]             192\n",
            "             ReLU-54           [-1, 96, 16, 16]               0\n",
            "           Conv2d-55           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-56          [-1, 144, 16, 16]             288\n",
            "             ReLU-57          [-1, 144, 16, 16]               0\n",
            "           Conv2d-58           [-1, 96, 16, 16]          13,824\n",
            "      BatchNorm2d-59           [-1, 96, 16, 16]             192\n",
            "             ReLU-60           [-1, 96, 16, 16]               0\n",
            "           Conv2d-61           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-62          [-1, 168, 16, 16]             336\n",
            "             ReLU-63          [-1, 168, 16, 16]               0\n",
            "           Conv2d-64           [-1, 96, 16, 16]          16,128\n",
            "      BatchNorm2d-65           [-1, 96, 16, 16]             192\n",
            "             ReLU-66           [-1, 96, 16, 16]               0\n",
            "           Conv2d-67           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-68          [-1, 192, 16, 16]             384\n",
            "             ReLU-69          [-1, 192, 16, 16]               0\n",
            "           Conv2d-70           [-1, 96, 16, 16]          18,432\n",
            "      BatchNorm2d-71           [-1, 96, 16, 16]             192\n",
            "             ReLU-72           [-1, 96, 16, 16]               0\n",
            "           Conv2d-73           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-74          [-1, 216, 16, 16]             432\n",
            "             ReLU-75          [-1, 216, 16, 16]               0\n",
            "           Conv2d-76           [-1, 96, 16, 16]          20,736\n",
            "      BatchNorm2d-77           [-1, 96, 16, 16]             192\n",
            "             ReLU-78           [-1, 96, 16, 16]               0\n",
            "           Conv2d-79           [-1, 24, 16, 16]          20,736\n",
            "      BatchNorm2d-80          [-1, 240, 16, 16]             480\n",
            "             ReLU-81          [-1, 240, 16, 16]               0\n",
            "           Conv2d-82          [-1, 120, 16, 16]          28,800\n",
            "        AvgPool2d-83            [-1, 120, 8, 8]               0\n",
            "      BatchNorm2d-84            [-1, 120, 8, 8]             240\n",
            "             ReLU-85            [-1, 120, 8, 8]               0\n",
            "           Conv2d-86             [-1, 96, 8, 8]          11,520\n",
            "      BatchNorm2d-87             [-1, 96, 8, 8]             192\n",
            "             ReLU-88             [-1, 96, 8, 8]               0\n",
            "           Conv2d-89             [-1, 24, 8, 8]          20,736\n",
            "      BatchNorm2d-90            [-1, 144, 8, 8]             288\n",
            "             ReLU-91            [-1, 144, 8, 8]               0\n",
            "           Conv2d-92             [-1, 96, 8, 8]          13,824\n",
            "      BatchNorm2d-93             [-1, 96, 8, 8]             192\n",
            "             ReLU-94             [-1, 96, 8, 8]               0\n",
            "           Conv2d-95             [-1, 24, 8, 8]          20,736\n",
            "      BatchNorm2d-96            [-1, 168, 8, 8]             336\n",
            "             ReLU-97            [-1, 168, 8, 8]               0\n",
            "           Conv2d-98             [-1, 96, 8, 8]          16,128\n",
            "      BatchNorm2d-99             [-1, 96, 8, 8]             192\n",
            "            ReLU-100             [-1, 96, 8, 8]               0\n",
            "          Conv2d-101             [-1, 24, 8, 8]          20,736\n",
            "     BatchNorm2d-102            [-1, 192, 8, 8]             384\n",
            "            ReLU-103            [-1, 192, 8, 8]               0\n",
            "          Conv2d-104             [-1, 96, 8, 8]          18,432\n",
            "     BatchNorm2d-105             [-1, 96, 8, 8]             192\n",
            "            ReLU-106             [-1, 96, 8, 8]               0\n",
            "          Conv2d-107             [-1, 24, 8, 8]          20,736\n",
            "     BatchNorm2d-108            [-1, 216, 8, 8]             432\n",
            "            ReLU-109            [-1, 216, 8, 8]               0\n",
            "          Conv2d-110             [-1, 96, 8, 8]          20,736\n",
            "     BatchNorm2d-111             [-1, 96, 8, 8]             192\n",
            "            ReLU-112             [-1, 96, 8, 8]               0\n",
            "          Conv2d-113             [-1, 24, 8, 8]          20,736\n",
            "     BatchNorm2d-114            [-1, 240, 8, 8]             480\n",
            "            ReLU-115            [-1, 240, 8, 8]               0\n",
            "          Conv2d-116             [-1, 96, 8, 8]          23,040\n",
            "     BatchNorm2d-117             [-1, 96, 8, 8]             192\n",
            "            ReLU-118             [-1, 96, 8, 8]               0\n",
            "          Conv2d-119             [-1, 24, 8, 8]          20,736\n",
            "     BatchNorm2d-120            [-1, 264, 8, 8]             528\n",
            "            ReLU-121            [-1, 264, 8, 8]               0\n",
            "          Conv2d-122            [-1, 132, 8, 8]          34,848\n",
            "       AvgPool2d-123            [-1, 132, 4, 4]               0\n",
            "     BatchNorm2d-124            [-1, 132, 4, 4]             264\n",
            "            ReLU-125            [-1, 132, 4, 4]               0\n",
            "          Conv2d-126             [-1, 96, 4, 4]          12,672\n",
            "     BatchNorm2d-127             [-1, 96, 4, 4]             192\n",
            "            ReLU-128             [-1, 96, 4, 4]               0\n",
            "          Conv2d-129             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-130            [-1, 156, 4, 4]             312\n",
            "            ReLU-131            [-1, 156, 4, 4]               0\n",
            "          Conv2d-132             [-1, 96, 4, 4]          14,976\n",
            "     BatchNorm2d-133             [-1, 96, 4, 4]             192\n",
            "            ReLU-134             [-1, 96, 4, 4]               0\n",
            "          Conv2d-135             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-136            [-1, 180, 4, 4]             360\n",
            "            ReLU-137            [-1, 180, 4, 4]               0\n",
            "          Conv2d-138             [-1, 96, 4, 4]          17,280\n",
            "     BatchNorm2d-139             [-1, 96, 4, 4]             192\n",
            "            ReLU-140             [-1, 96, 4, 4]               0\n",
            "          Conv2d-141             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-142            [-1, 204, 4, 4]             408\n",
            "            ReLU-143            [-1, 204, 4, 4]               0\n",
            "          Conv2d-144             [-1, 96, 4, 4]          19,584\n",
            "     BatchNorm2d-145             [-1, 96, 4, 4]             192\n",
            "            ReLU-146             [-1, 96, 4, 4]               0\n",
            "          Conv2d-147             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-148            [-1, 228, 4, 4]             456\n",
            "            ReLU-149            [-1, 228, 4, 4]               0\n",
            "          Conv2d-150             [-1, 96, 4, 4]          21,888\n",
            "     BatchNorm2d-151             [-1, 96, 4, 4]             192\n",
            "            ReLU-152             [-1, 96, 4, 4]               0\n",
            "          Conv2d-153             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-154            [-1, 252, 4, 4]             504\n",
            "            ReLU-155            [-1, 252, 4, 4]               0\n",
            "          Conv2d-156             [-1, 96, 4, 4]          24,192\n",
            "     BatchNorm2d-157             [-1, 96, 4, 4]             192\n",
            "            ReLU-158             [-1, 96, 4, 4]               0\n",
            "          Conv2d-159             [-1, 24, 4, 4]          20,736\n",
            "     BatchNorm2d-160            [-1, 276, 4, 4]             552\n",
            "            ReLU-161            [-1, 276, 4, 4]               0\n",
            "AdaptiveAvgPool2d-162            [-1, 276, 1, 1]               0\n",
            "          Conv2d-163             [-1, 10, 1, 1]           2,770\n",
            "================================================================\n",
            "Total params: 964,426\n",
            "Trainable params: 964,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 41.24\n",
            "Params size (MB): 3.68\n",
            "Estimated Total Size (MB): 44.93\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiC6Ypf3ZPZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9413200-e3d5-4f48-f9e4-f147f51e3a5f"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self,channel,batch_norm=False):\n",
        "        super(Inception, self).__init__()\n",
        "        if batch_norm==False:\n",
        "            self.branch1x1=nn.Conv2d(channel[0],channel[1],kernel_size=(1,1),stride=1)\n",
        "\n",
        "            self.branch3x3_1=nn.Conv2d(channel[0],channel[2],kernel_size=(1,1),stride=1)\n",
        "            self.branch3x3_2=nn.Conv2d(channel[2],channel[3],kernel_size=(3,3),stride=1,padding=1)\n",
        "\n",
        "            self.branch5x5_1=nn.Conv2d(channel[0],channel[4],kernel_size=(1,1),stride=1)\n",
        "            self.branch5x5_2=nn.Conv2d(channel[4],channel[5],kernel_size=(5,5),stride=1,padding=2)\n",
        "\n",
        "            self.branchM_1=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
        "            self.branchM_2=nn.Conv2d(channel[0],channel[6],kernel_size=(1,1),stride=1)\n",
        "        else:\n",
        "            self.branch1x1=BasicConv2d(channel[0],channel[1],kernel_size=(1,1),stride=1)\n",
        "\n",
        "            self.branch3x3_1=BasicConv2d(channel[0],channel[2],kernel_size=(1,1),stride=1)\n",
        "            self.branch3x3_2=BasicConv2d(channel[2],channel[3],kernel_size=(3,3),stride=1,padding=1)\n",
        "\n",
        "            self.branch5x5_1=BasicConv2d(channel[0],channel[4],kernel_size=(1,1),stride=1)\n",
        "            self.branch5x5_2=BasicConv2d(channel[4],channel[5],kernel_size=(5,5),stride=1,padding=2)\n",
        "\n",
        "            self.branchM_1=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
        "            self.branchM_2=BasicConv2d(channel[0],channel[6],kernel_size=(1,1),stride=1)\n",
        "\n",
        "        self.relu=nn.ReLU(True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        branch1x1=self.relu(self.branch1x1(x))\n",
        "\n",
        "        branch3x3_1=self.relu(self.branch3x3_1(x))\n",
        "        branch3x3_2=self.relu(self.branch3x3_2(branch3x3_1))\n",
        "\n",
        "        branch5x5_1=self.relu(self.branch5x5_1(x))\n",
        "        branch5x5_2=self.relu(self.branch5x5_2(branch5x5_1))\n",
        "\n",
        "        branchM_1=self.relu(self.branchM_1(x))\n",
        "        branchM_2=self.relu(self.branchM_2(branchM_1))\n",
        "\n",
        "        outputs = [branch1x1, branch3x3_2, branch5x5_2, branchM_2]\n",
        "\n",
        "        return torch.cat(outputs,1)\n",
        "\n",
        "\n",
        "channel=[\n",
        "    [192, 64, 96,128, 16, 32, 32],#3a\n",
        "    [256,128,128,192, 32, 96, 64],#3b\n",
        "    [480,192, 96,208, 16, 48, 64],#4a\n",
        "    [512,160,112,224, 24, 64, 64],#4b\n",
        "    [512,128,128,256, 24, 64, 64],#4c\n",
        "    [512,112,144,288, 32, 64, 64],#4d\n",
        "    [528,256,160,320, 32,128,128],#4e\n",
        "    [832,256,160,320, 32,128,128],#5a\n",
        "    [832,384,192,384, 48,128,128] #5b\n",
        "]\n",
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self,num_classes=1000,batch_norm=False):\n",
        "        super(InceptionNet, self).__init__()\n",
        "        \n",
        "        if num_classes==10:\n",
        "            channel[0][0]=64\n",
        "            self.begin=nn.Sequential(\n",
        "                nn.Conv2d(3,64,kernel_size=3,stride=1),\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(64,64,kernel_size=3,stride=1),\n",
        "                nn.ReLU(True)\n",
        "            )\n",
        "\n",
        "            self.auxout1=nn.Sequential(\n",
        "                nn.Conv2d(512,512,kernel_size=5,stride=3), #4x4x512\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(512,128,kernel_size=1),          #4x4x128\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(128, 10,kernel_size=4)           #1x1x10\n",
        "            )\n",
        "            self.auxout2=nn.Sequential(\n",
        "                nn.Conv2d(528,528,kernel_size=5,stride=3), #4x4x528,\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(528,128,kernel_size=1),          #4x4x128,\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(128, 10,kernel_size=4)           #1x1x10\n",
        "            )\n",
        "        else:\n",
        "            self.begin=nn.Sequential(\n",
        "                nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3),\n",
        "                nn.ReLU(True),\n",
        "                nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
        "                nn.Conv2d(64,192,kernel_size=3,stride=1,padding=1),\n",
        "                nn.ReLU(True),\n",
        "                nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
        "            )\n",
        "            self.auxout1=nn.Sequential(\n",
        "                nn.Conv2d(512,512,kernel_size=5,stride=3),#4x4x512\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(512,128,kernel_size=1),        #4x4x128 \n",
        "                nn.ReLU(True)  \n",
        "            )\n",
        "            self.auxout12=nn.Sequential(\n",
        "                nn.Linear(2048,1024),           \n",
        "                nn.Dropout(0.5),\n",
        "                nn.linear(1024,num_classes)  \n",
        "            )\n",
        "                \n",
        "            self.auxout2=nn.Sequential(\n",
        "                nn.Conv2d(528,528,kernel_size=5,stride=3),#4x4x528\n",
        "                nn.ReLU(True),\n",
        "                nn.Conv2d(528,128,kernel_size=1),         #4x4x128   \n",
        "                nn.ReLU(True)\n",
        "            )\n",
        "            self.auxout22=nn.Sequential(\n",
        "                nn.Linear(2048,1024),           \n",
        "                nn.Dropout(0.5),\n",
        "                nn.linear(1024,num_classes)  \n",
        "            )\n",
        "\n",
        "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "        self.inception3a=Inception(channel[0],batch_norm)\n",
        "        self.inception3b=Inception(channel[1],batch_norm)\n",
        "\n",
        "        self.inception4a=Inception(channel[2],batch_norm)\n",
        "        self.inception4b=Inception(channel[3],batch_norm)\n",
        "        self.inception4c=Inception(channel[4],batch_norm)\n",
        "        self.inception4d=Inception(channel[5],batch_norm)\n",
        "        self.inception4e=Inception(channel[6],batch_norm)\n",
        "        \n",
        "        self.inception5a=Inception(channel[7],batch_norm)\n",
        "        self.inception5b=Inception(channel[8],batch_norm)\n",
        "\n",
        "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "        \n",
        "        self.conv1x1=nn.Conv2d(1024,num_classes,kernel_size=1)\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "        '''\n",
        "        #follow the original papar,but for the computation ,I do not use it\n",
        "        self.drop=nn.Dropout()\n",
        "        self.linear=nn.Linear(1024,1000)\n",
        "        '''\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m,nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight,1)\n",
        "                nn.init.constant_(m.bias,0)\n",
        "            elif isinstance(m,nn.Linear):\n",
        "                nn.init.normal_(m.weight,0,0.01)\n",
        "                nn.init.constant_(m.bias,0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.begin(x)\n",
        "\n",
        "        x=self.inception3a(x)\n",
        "        x=self.inception3b(x)\n",
        "        x=self.maxpool(x)\n",
        "\n",
        "        x=self.inception4a(x)\n",
        "        auxout1=self.auxout1(x)\n",
        "        auxout1=auxout1.view(auxout1.size(0),-1)\n",
        "        #if you use this network to train on ImageNet you should add this code\n",
        "        #auxout1=self.auxout12(auxout1)\n",
        "        x=self.inception4b(x)\n",
        "        x=self.inception4c(x)\n",
        "        x=self.inception4d(x)\n",
        "\n",
        "        auxout2=self.auxout2(x)\n",
        "        auxout2=auxout2.view(auxout2.size(0),-1)\n",
        "        #if you use this network to train on ImageNet you should add this code\n",
        "        #auxout2=self.auxout22(auxout2)\n",
        "        x=self.inception4e(x)\n",
        "        x=self.maxpool(x)\n",
        "\n",
        "        x=self.inception5a(x)\n",
        "        x=self.inception5b(x)\n",
        "        x=self.avgpool(x)\n",
        "\n",
        "        outputs=self.conv1x1(x)\n",
        "        outputs=outputs.view(outputs.size(0),-1)\n",
        "\n",
        "        return outputs,auxout1,auxout2\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net=InceptionNet(num_classes=10,batch_norm=True)\n",
        "    print(net)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "InceptionNet(\n",
            "  (begin): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "  )\n",
            "  (auxout1): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(3, 3))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(128, 10, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            "  (auxout2): Sequential(\n",
            "    (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(3, 3))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(128, 10, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (inception3a): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception4a): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception5a): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branchM_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    (branchM_2): BasicConv2d(\n",
            "      (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (conv1x1): Conv2d(1024, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbthX7YmdL5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "        net=SqueezeNet(version=1.1, num_classes=100)\n",
        "    print(net)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT2B-IOdTm-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15de61d6a37e436292e847af819c8f36",
            "90551952a354480c9902003946294c2d",
            "40f46c13ace04614a19fdf72021416e3",
            "43157e911e254aca86bf1a23f21df351",
            "3fd2edff48d7471990f264dae05ff2da",
            "5e6e3987799a4f9591e4b94b64b99790",
            "ab34792827074e59a10ddd95e05d7baf",
            "4fb37b7568be4db6b3e13a7b5d830662"
          ]
        },
        "outputId": "97f818b9-7204-4d1f-c676-e0f85b6050ca"
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from collections import OrderedDict\n",
        "\n",
        "__all__ = ['DPN', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107']\n",
        "\n",
        "pretrained_settings = {\n",
        "    'dpn68': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-4af7d88d2.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    },\n",
        "    'dpn68b': {\n",
        "        'imagenet+5k': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68b_extra-363ab9c19.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    },\n",
        "    'dpn92': {\n",
        "        # 'imagenet': {\n",
        "        #     'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn68-66bebafa7.pth',\n",
        "        #     'input_space': 'RGB',\n",
        "        #     'input_size': [3, 224, 224],\n",
        "        #     'input_range': [0, 1],\n",
        "        #     'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "        #     'std': [1 / (.0167 * 255)] * 3,\n",
        "        #     'num_classes': 1000\n",
        "        # },\n",
        "        'imagenet+5k': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn92_extra-fda993c95.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    },\n",
        "    'dpn98': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn98-722954780.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    },\n",
        "    'dpn131': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn131-7af84be88.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    },\n",
        "    'dpn107': {\n",
        "        'imagenet+5k': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/dpn107_extra-b7f9f4cc9.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [124 / 255, 117 / 255, 104 / 255],\n",
        "            'std': [1 / (.0167 * 255)] * 3,\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "def dpn68(num_classes=1000, pretrained='imagenet'):\n",
        "    model = DPN(\n",
        "        small=True, num_init_features=10, k_r=128, groups=32,\n",
        "        k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn68'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "def dpn68b(num_classes=1000, pretrained='imagenet+5k'):\n",
        "    model = DPN(\n",
        "        small=True, num_init_features=10, k_r=128, groups=32,\n",
        "        b=True, k_sec=(3, 4, 12, 3), inc_sec=(16, 32, 32, 64),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn68b'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "def dpn92(num_classes=1000, pretrained='imagenet+5k'):\n",
        "    model = DPN(\n",
        "        num_init_features=64, k_r=96, groups=32,\n",
        "        k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn92'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "def dpn98(num_classes=1000, pretrained='imagenet'):\n",
        "    model = DPN(\n",
        "        num_init_features=96, k_r=160, groups=40,\n",
        "        k_sec=(3, 6, 20, 3), inc_sec=(16, 32, 32, 128),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn98'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "def dpn131(num_classes=1000, pretrained='imagenet'):\n",
        "    model = DPN(\n",
        "        num_init_features=128, k_r=160, groups=40,\n",
        "        k_sec=(4, 8, 28, 3), inc_sec=(16, 32, 32, 128),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn131'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "def dpn107(num_classes=1000, pretrained='imagenet+5k'):\n",
        "    model = DPN(\n",
        "        num_init_features=128, k_r=200, groups=50,\n",
        "        k_sec=(4, 8, 20, 3), inc_sec=(20, 64, 64, 128),\n",
        "        num_classes=num_classes, test_time_pool=True)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['dpn107'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "\n",
        "class CatBnAct(nn.Module):\n",
        "    def __init__(self, in_chs, activation_fn=nn.ReLU(inplace=True)):\n",
        "        super(CatBnAct, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n",
        "        self.act = activation_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n",
        "        return self.act(self.bn(x))\n",
        "\n",
        "\n",
        "class BnActConv2d(nn.Module):\n",
        "    def __init__(self, in_chs, out_chs, kernel_size, stride,\n",
        "                 padding=0, groups=1, activation_fn=nn.ReLU(inplace=True)):\n",
        "        super(BnActConv2d, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_chs, eps=0.001)\n",
        "        self.act = activation_fn\n",
        "        self.conv = nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(self.act(self.bn(x)))\n",
        "\n",
        "\n",
        "class InputBlock(nn.Module):\n",
        "    def __init__(self, num_init_features, kernel_size=7,\n",
        "                 padding=3, activation_fn=nn.ReLU(inplace=True)):\n",
        "        super(InputBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            3, num_init_features, kernel_size=kernel_size, stride=2, padding=padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(num_init_features, eps=0.001)\n",
        "        self.act = activation_fn\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DualPathBlock(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, groups, block_type='normal', b=False):\n",
        "        super(DualPathBlock, self).__init__()\n",
        "        self.num_1x1_c = num_1x1_c\n",
        "        self.inc = inc\n",
        "        self.b = b\n",
        "        if block_type is 'proj':\n",
        "            self.key_stride = 1\n",
        "            self.has_proj = True\n",
        "        elif block_type is 'down':\n",
        "            self.key_stride = 2\n",
        "            self.has_proj = True\n",
        "        else:\n",
        "            assert block_type is 'normal'\n",
        "            self.key_stride = 1\n",
        "            self.has_proj = False\n",
        "\n",
        "        if self.has_proj:\n",
        "            # Using different member names here to allow easier parameter key matching for conversion\n",
        "            if self.key_stride == 2:\n",
        "                self.c1x1_w_s2 = BnActConv2d(\n",
        "                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=2)\n",
        "            else:\n",
        "                self.c1x1_w_s1 = BnActConv2d(\n",
        "                    in_chs=in_chs, out_chs=num_1x1_c + 2 * inc, kernel_size=1, stride=1)\n",
        "        self.c1x1_a = BnActConv2d(in_chs=in_chs, out_chs=num_1x1_a, kernel_size=1, stride=1)\n",
        "        self.c3x3_b = BnActConv2d(\n",
        "            in_chs=num_1x1_a, out_chs=num_3x3_b, kernel_size=3,\n",
        "            stride=self.key_stride, padding=1, groups=groups)\n",
        "        if b:\n",
        "            self.c1x1_c = CatBnAct(in_chs=num_3x3_b)\n",
        "            self.c1x1_c1 = nn.Conv2d(num_3x3_b, num_1x1_c, kernel_size=1, bias=False)\n",
        "            self.c1x1_c2 = nn.Conv2d(num_3x3_b, inc, kernel_size=1, bias=False)\n",
        "        else:\n",
        "            self.c1x1_c = BnActConv2d(in_chs=num_3x3_b, out_chs=num_1x1_c + inc, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_in = torch.cat(x, dim=1) if isinstance(x, tuple) else x\n",
        "        if self.has_proj:\n",
        "            if self.key_stride == 2:\n",
        "                x_s = self.c1x1_w_s2(x_in)\n",
        "            else:\n",
        "                x_s = self.c1x1_w_s1(x_in)\n",
        "            x_s1 = x_s[:, :self.num_1x1_c, :, :]\n",
        "            x_s2 = x_s[:, self.num_1x1_c:, :, :]\n",
        "        else:\n",
        "            x_s1 = x[0]\n",
        "            x_s2 = x[1]\n",
        "        x_in = self.c1x1_a(x_in)\n",
        "        x_in = self.c3x3_b(x_in)\n",
        "        if self.b:\n",
        "            x_in = self.c1x1_c(x_in)\n",
        "            out1 = self.c1x1_c1(x_in)\n",
        "            out2 = self.c1x1_c2(x_in)\n",
        "        else:\n",
        "            x_in = self.c1x1_c(x_in)\n",
        "            out1 = x_in[:, :self.num_1x1_c, :, :]\n",
        "            out2 = x_in[:, self.num_1x1_c:, :, :]\n",
        "        resid = x_s1 + out1\n",
        "        dense = torch.cat([x_s2, out2], dim=1)\n",
        "        return resid, dense\n",
        "\n",
        "\n",
        "class DPN(nn.Module):\n",
        "    def __init__(self, small=False, num_init_features=64, k_r=96, groups=32,\n",
        "                 b=False, k_sec=(3, 4, 20, 3), inc_sec=(16, 32, 24, 128),\n",
        "                 num_classes=1000, test_time_pool=False):\n",
        "        super(DPN, self).__init__()\n",
        "        self.test_time_pool = test_time_pool\n",
        "        self.b = b\n",
        "        bw_factor = 1 if small else 4\n",
        "\n",
        "        blocks = OrderedDict()\n",
        "\n",
        "        # conv1\n",
        "        if small:\n",
        "            blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=3, padding=1)\n",
        "        else:\n",
        "            blocks['conv1_1'] = InputBlock(num_init_features, kernel_size=7, padding=3)\n",
        "\n",
        "        # conv2\n",
        "        bw = 64 * bw_factor\n",
        "        inc = inc_sec[0]\n",
        "        r = (k_r * bw) // (64 * bw_factor)\n",
        "        blocks['conv2_1'] = DualPathBlock(num_init_features, r, r, bw, inc, groups, 'proj', b)\n",
        "        in_chs = bw + 3 * inc\n",
        "        for i in range(2, k_sec[0] + 1):\n",
        "            blocks['conv2_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n",
        "            in_chs += inc\n",
        "\n",
        "        # conv3\n",
        "        bw = 128 * bw_factor\n",
        "        inc = inc_sec[1]\n",
        "        r = (k_r * bw) // (64 * bw_factor)\n",
        "        blocks['conv3_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n",
        "        in_chs = bw + 3 * inc\n",
        "        for i in range(2, k_sec[1] + 1):\n",
        "            blocks['conv3_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n",
        "            in_chs += inc\n",
        "\n",
        "        # conv4\n",
        "        bw = 256 * bw_factor\n",
        "        inc = inc_sec[2]\n",
        "        r = (k_r * bw) // (64 * bw_factor)\n",
        "        blocks['conv4_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n",
        "        in_chs = bw + 3 * inc\n",
        "        for i in range(2, k_sec[2] + 1):\n",
        "            blocks['conv4_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n",
        "            in_chs += inc\n",
        "\n",
        "        # conv5\n",
        "        bw = 512 * bw_factor\n",
        "        inc = inc_sec[3]\n",
        "        r = (k_r * bw) // (64 * bw_factor)\n",
        "        blocks['conv5_1'] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'down', b)\n",
        "        in_chs = bw + 3 * inc\n",
        "        for i in range(2, k_sec[3] + 1):\n",
        "            blocks['conv5_' + str(i)] = DualPathBlock(in_chs, r, r, bw, inc, groups, 'normal', b)\n",
        "            in_chs += inc\n",
        "        blocks['conv5_bn_ac'] = CatBnAct(in_chs)\n",
        "\n",
        "        self.features = nn.Sequential(blocks)\n",
        "\n",
        "        # Using 1x1 conv for the FC layer to allow the extra pooling scheme\n",
        "        self.last_linear = nn.Conv2d(in_chs, num_classes, kernel_size=1, bias=True)\n",
        "\n",
        "    def logits(self, features):\n",
        "        if not self.training and self.test_time_pool:\n",
        "            x = F.avg_pool2d(features, kernel_size=7, stride=1)\n",
        "            out = self.last_linear(x)\n",
        "            # The extra test time pool should be pooling an img_size//32 - 6 size patch\n",
        "            out = adaptive_avgmax_pool2d(out, pool_type='avgmax')\n",
        "        else:\n",
        "            x = adaptive_avgmax_pool2d(features, pool_type='avg')\n",
        "            out = self.last_linear(x)\n",
        "        return out.view(out.size(0), -1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\"\"\" PyTorch selectable adaptive pooling\n",
        "Adaptive pooling with the ability to select the type of pooling from:\n",
        "    * 'avg' - Average pooling\n",
        "    * 'max' - Max pooling\n",
        "    * 'avgmax' - Sum of average and max pooling re-scaled by 0.5\n",
        "    * 'avgmaxc' - Concatenation of average and max pooling along feature dim, doubles feature dim\n",
        "Both a functional and a nn.Module version of the pooling is provided.\n",
        "Author: Ross Wightman (rwightman)\n",
        "\"\"\"\n",
        "\n",
        "def pooling_factor(pool_type='avg'):\n",
        "    return 2 if pool_type == 'avgmaxc' else 1\n",
        "\n",
        "\n",
        "def adaptive_avgmax_pool2d(x, pool_type='avg', padding=0, count_include_pad=False):\n",
        "    \"\"\"Selectable global pooling function with dynamic input kernel size\n",
        "    \"\"\"\n",
        "    if pool_type == 'avgmaxc':\n",
        "        x = torch.cat([\n",
        "            F.avg_pool2d(\n",
        "                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad),\n",
        "            F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
        "        ], dim=1)\n",
        "    elif pool_type == 'avgmax':\n",
        "        x_avg = F.avg_pool2d(\n",
        "                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n",
        "        x_max = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
        "        x = 0.5 * (x_avg + x_max)\n",
        "    elif pool_type == 'max':\n",
        "        x = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
        "    else:\n",
        "        if pool_type != 'avg':\n",
        "            print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n",
        "        x = F.avg_pool2d(\n",
        "            x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n",
        "    return x\n",
        "\n",
        "\n",
        "class AdaptiveAvgMaxPool2d(torch.nn.Module):\n",
        "    \"\"\"Selectable global pooling layer with dynamic input kernel size\n",
        "    \"\"\"\n",
        "    def __init__(self, output_size=1, pool_type='avg'):\n",
        "        super(AdaptiveAvgMaxPool2d, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.pool_type = pool_type\n",
        "        if pool_type == 'avgmaxc' or pool_type == 'avgmax':\n",
        "            self.pool = nn.ModuleList([nn.AdaptiveAvgPool2d(output_size), nn.AdaptiveMaxPool2d(output_size)])\n",
        "        elif pool_type == 'max':\n",
        "            self.pool = nn.AdaptiveMaxPool2d(output_size)\n",
        "        else:\n",
        "            if pool_type != 'avg':\n",
        "                print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n",
        "            self.pool = nn.AdaptiveAvgPool2d(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pool_type == 'avgmaxc':\n",
        "            x = torch.cat([p(x) for p in self.pool], dim=1)\n",
        "        elif self.pool_type == 'avgmax':\n",
        "            x = 0.5 * torch.sum(torch.stack([p(x) for p in self.pool]), 0).squeeze(dim=0)\n",
        "        else:\n",
        "            x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "    def factor(self):\n",
        "        return pooling_factor(self.pool_type)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + 'output_size=' + str(self.output_size) \\\n",
        "               + ', pool_type=' + self.pool_type + ')'\n",
        "\n",
        "\n",
        "net=dpn68(num_classes=1000, pretrained='imagenet')\n",
        "print(net)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/dpn68-4af7d88d2.pth\" to /root/.cache/torch/checkpoints/dpn68-4af7d88d2.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15de61d6a37e436292e847af819c8f36",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50761996.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DPN(\n",
            "  (features): Sequential(\n",
            "    (conv1_1): InputBlock(\n",
            "      (conv): Conv2d(3, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(10, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (conv2_1): DualPathBlock(\n",
            "      (c1x1_w_s1): BnActConv2d(\n",
            "        (bn): BatchNorm2d(10, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(10, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(10, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(10, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv2_2): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv2_3): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv3_1): DualPathBlock(\n",
            "      (c1x1_w_s2): BnActConv2d(\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(144, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv3_2): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv3_3): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv3_4): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_1): DualPathBlock(\n",
            "      (c1x1_w_s2): BnActConv2d(\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(320, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_2): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(352, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_3): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_4): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(416, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(416, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_5): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(448, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_6): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(480, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_7): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_8): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(544, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(544, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_9): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(576, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_10): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(608, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(608, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_11): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(640, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv4_12): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(672, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv5_1): DualPathBlock(\n",
            "      (c1x1_w_s2): BnActConv2d(\n",
            "        (bn): BatchNorm2d(704, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(704, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(704, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(704, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv5_2): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(704, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(704, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv5_3): DualPathBlock(\n",
            "      (c1x1_a): BnActConv2d(\n",
            "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(768, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (c3x3_b): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      )\n",
            "      (c1x1_c): BnActConv2d(\n",
            "        (bn): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (conv5_bn_ac): CatBnAct(\n",
            "      (bn): BatchNorm2d(832, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (last_linear): Conv2d(832, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Z0m3OlUozg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2849fdef-63d1-4807-e6cc-b849740f470e"
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import os\n",
        "import sys\n",
        "\n",
        "__all__ = ['BNInception', 'bninception']\n",
        "\n",
        "pretrained_settings = {\n",
        "    'bninception': {\n",
        "        'imagenet': {\n",
        "            # Was ported using python2 (may trigger warning)\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/bn_inception-52deb4733.pth',\n",
        "            # 'url': 'http://yjxiong.me/others/bn_inception-9f5701afb96c8044.pth',\n",
        "            'input_space': 'BGR',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 255],\n",
        "            'mean': [104, 117, 128],\n",
        "            'std': [1, 1, 1],\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "class BNInception(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(BNInception, self).__init__()\n",
        "        inplace = True\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.conv1_relu_7x7 = nn.ReLU (inplace)\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d ((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.conv2_3x3_reduce = nn.Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv2_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.conv2_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.conv2_3x3 = nn.Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv2_3x3_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.conv2_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.pool2_3x3_s2 = nn.MaxPool2d ((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_3a_1x1 = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_1x1_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3a_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_3a_3x3_reduce = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3a_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3a_3x3 = nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_3x3_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3a_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_3a_double_3x3_reduce = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_double_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3a_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_1_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_3a_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_2_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3a_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_3a_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_3a_pool_proj = nn.Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_pool_proj_bn = nn.BatchNorm2d(32, affine=True)\n",
        "        self.inception_3a_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_3b_1x1 = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_1x1_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3b_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_3b_3x3_reduce = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3b_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3b_3x3 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_3x3_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3b_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_3b_double_3x3_reduce = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_double_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3b_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_1_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_3b_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_2_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3b_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_3b_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_3b_pool_proj = nn.Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_pool_proj_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3b_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_3c_3x3_reduce = nn.Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_3x3_reduce_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_3c_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3c_3x3 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_3c_3x3_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_3c_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_3c_double_3x3_reduce = nn.Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_double_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_3c_double_3x3_1 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_1_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_3c_double_3x3_2 = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_2_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_3c_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_3c_pool = nn.MaxPool2d ((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_4a_1x1 = nn.Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_1x1_bn = nn.BatchNorm2d(224, affine=True)\n",
        "        self.inception_4a_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_4a_3x3_reduce = nn.Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_3x3_reduce_bn = nn.BatchNorm2d(64, affine=True)\n",
        "        self.inception_4a_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4a_3x3 = nn.Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_3x3_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_4a_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_4a_double_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_double_3x3_reduce_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4a_double_3x3_1 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_double_3x3_1_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_4a_double_3x3_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4a_double_3x3_2_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4a_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_4a_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4a_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4a_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4a_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_4b_1x1 = nn.Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_1x1_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4b_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_4b_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_3x3_reduce_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_4b_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4b_3x3 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_3x3_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4b_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_4b_double_3x3_reduce = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_double_3x3_reduce_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4b_double_3x3_1 = nn.Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_double_3x3_1_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_4b_double_3x3_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4b_double_3x3_2_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4b_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_4b_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4b_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4b_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4b_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_4c_1x1 = nn.Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_1x1_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_4c_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_4c_3x3_reduce = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_3x3_reduce_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4c_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4c_3x3 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_3x3_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_4c_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_4c_double_3x3_reduce = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_double_3x3_reduce_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4c_double_3x3_1 = nn.Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_double_3x3_1_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_4c_double_3x3_2 = nn.Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4c_double_3x3_2_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_4c_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_4c_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4c_pool_proj = nn.Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4c_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4c_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_4d_1x1 = nn.Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_1x1_bn = nn.BatchNorm2d(96, affine=True)\n",
        "        self.inception_4d_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_4d_3x3_reduce = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_3x3_reduce_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4d_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4d_3x3 = nn.Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_3x3_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4d_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_4d_double_3x3_reduce = nn.Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_double_3x3_reduce_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4d_double_3x3_1 = nn.Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_double_3x3_1_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_4d_double_3x3_2 = nn.Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4d_double_3x3_2_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4d_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_4d_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_4d_pool_proj = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4d_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4d_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_4e_3x3_reduce = nn.Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4e_3x3_reduce_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_4e_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4e_3x3 = nn.Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_4e_3x3_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4e_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_4e_double_3x3_reduce = nn.Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_4e_double_3x3_reduce_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_4e_double_3x3_1 = nn.Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_4e_double_3x3_1_bn = nn.BatchNorm2d(256, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_4e_double_3x3_2 = nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.inception_4e_double_3x3_2_bn = nn.BatchNorm2d(256, affine=True)\n",
        "        self.inception_4e_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_4e_pool = nn.MaxPool2d ((3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_5a_1x1 = nn.Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_1x1_bn = nn.BatchNorm2d(352, affine=True)\n",
        "        self.inception_5a_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_5a_3x3_reduce = nn.Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_3x3_reduce_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_5a_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_5a_3x3 = nn.Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_3x3_bn = nn.BatchNorm2d(320, affine=True)\n",
        "        self.inception_5a_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_5a_double_3x3_reduce = nn.Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_double_3x3_reduce_bn = nn.BatchNorm2d(160, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_5a_double_3x3_1 = nn.Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_double_3x3_1_bn = nn.BatchNorm2d(224, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_5a_double_3x3_2 = nn.Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5a_double_3x3_2_bn = nn.BatchNorm2d(224, affine=True)\n",
        "        self.inception_5a_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_5a_pool = nn.AvgPool2d (3, stride=1, padding=1, ceil_mode=True, count_include_pad=True)\n",
        "        self.inception_5a_pool_proj = nn.Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5a_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_5a_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.inception_5b_1x1 = nn.Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_1x1_bn = nn.BatchNorm2d(352, affine=True)\n",
        "        self.inception_5b_relu_1x1 = nn.ReLU (inplace)\n",
        "        self.inception_5b_3x3_reduce = nn.Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_3x3_reduce_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_5b_relu_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_5b_3x3 = nn.Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_3x3_bn = nn.BatchNorm2d(320, affine=True)\n",
        "        self.inception_5b_relu_3x3 = nn.ReLU (inplace)\n",
        "        self.inception_5b_double_3x3_reduce = nn.Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_double_3x3_reduce_bn = nn.BatchNorm2d(192, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_reduce = nn.ReLU (inplace)\n",
        "        self.inception_5b_double_3x3_1 = nn.Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_double_3x3_1_bn = nn.BatchNorm2d(224, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_1 = nn.ReLU (inplace)\n",
        "        self.inception_5b_double_3x3_2 = nn.Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_5b_double_3x3_2_bn = nn.BatchNorm2d(224, affine=True)\n",
        "        self.inception_5b_relu_double_3x3_2 = nn.ReLU (inplace)\n",
        "        self.inception_5b_pool = nn.MaxPool2d ((3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
        "        self.inception_5b_pool_proj = nn.Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_5b_pool_proj_bn = nn.BatchNorm2d(128, affine=True)\n",
        "        self.inception_5b_relu_pool_proj = nn.ReLU (inplace)\n",
        "        self.last_linear = nn.Linear (1024, num_classes)\n",
        "\n",
        "    def features(self, input):\n",
        "        conv1_7x7_s2_out = self.conv1_7x7_s2(input)\n",
        "        conv1_7x7_s2_bn_out = self.conv1_7x7_s2_bn(conv1_7x7_s2_out)\n",
        "        conv1_relu_7x7_out = self.conv1_relu_7x7(conv1_7x7_s2_bn_out)\n",
        "        pool1_3x3_s2_out = self.pool1_3x3_s2(conv1_relu_7x7_out)\n",
        "        conv2_3x3_reduce_out = self.conv2_3x3_reduce(pool1_3x3_s2_out)\n",
        "        conv2_3x3_reduce_bn_out = self.conv2_3x3_reduce_bn(conv2_3x3_reduce_out)\n",
        "        conv2_relu_3x3_reduce_out = self.conv2_relu_3x3_reduce(conv2_3x3_reduce_bn_out)\n",
        "        conv2_3x3_out = self.conv2_3x3(conv2_relu_3x3_reduce_out)\n",
        "        conv2_3x3_bn_out = self.conv2_3x3_bn(conv2_3x3_out)\n",
        "        conv2_relu_3x3_out = self.conv2_relu_3x3(conv2_3x3_bn_out)\n",
        "        pool2_3x3_s2_out = self.pool2_3x3_s2(conv2_relu_3x3_out)\n",
        "        inception_3a_1x1_out = self.inception_3a_1x1(pool2_3x3_s2_out)\n",
        "        inception_3a_1x1_bn_out = self.inception_3a_1x1_bn(inception_3a_1x1_out)\n",
        "        inception_3a_relu_1x1_out = self.inception_3a_relu_1x1(inception_3a_1x1_bn_out)\n",
        "        inception_3a_3x3_reduce_out = self.inception_3a_3x3_reduce(pool2_3x3_s2_out)\n",
        "        inception_3a_3x3_reduce_bn_out = self.inception_3a_3x3_reduce_bn(inception_3a_3x3_reduce_out)\n",
        "        inception_3a_relu_3x3_reduce_out = self.inception_3a_relu_3x3_reduce(inception_3a_3x3_reduce_bn_out)\n",
        "        inception_3a_3x3_out = self.inception_3a_3x3(inception_3a_relu_3x3_reduce_out)\n",
        "        inception_3a_3x3_bn_out = self.inception_3a_3x3_bn(inception_3a_3x3_out)\n",
        "        inception_3a_relu_3x3_out = self.inception_3a_relu_3x3(inception_3a_3x3_bn_out)\n",
        "        inception_3a_double_3x3_reduce_out = self.inception_3a_double_3x3_reduce(pool2_3x3_s2_out)\n",
        "        inception_3a_double_3x3_reduce_bn_out = self.inception_3a_double_3x3_reduce_bn(inception_3a_double_3x3_reduce_out)\n",
        "        inception_3a_relu_double_3x3_reduce_out = self.inception_3a_relu_double_3x3_reduce(inception_3a_double_3x3_reduce_bn_out)\n",
        "        inception_3a_double_3x3_1_out = self.inception_3a_double_3x3_1(inception_3a_relu_double_3x3_reduce_out)\n",
        "        inception_3a_double_3x3_1_bn_out = self.inception_3a_double_3x3_1_bn(inception_3a_double_3x3_1_out)\n",
        "        inception_3a_relu_double_3x3_1_out = self.inception_3a_relu_double_3x3_1(inception_3a_double_3x3_1_bn_out)\n",
        "        inception_3a_double_3x3_2_out = self.inception_3a_double_3x3_2(inception_3a_relu_double_3x3_1_out)\n",
        "        inception_3a_double_3x3_2_bn_out = self.inception_3a_double_3x3_2_bn(inception_3a_double_3x3_2_out)\n",
        "        inception_3a_relu_double_3x3_2_out = self.inception_3a_relu_double_3x3_2(inception_3a_double_3x3_2_bn_out)\n",
        "        inception_3a_pool_out = self.inception_3a_pool(pool2_3x3_s2_out)\n",
        "        inception_3a_pool_proj_out = self.inception_3a_pool_proj(inception_3a_pool_out)\n",
        "        inception_3a_pool_proj_bn_out = self.inception_3a_pool_proj_bn(inception_3a_pool_proj_out)\n",
        "        inception_3a_relu_pool_proj_out = self.inception_3a_relu_pool_proj(inception_3a_pool_proj_bn_out)\n",
        "        inception_3a_output_out = torch.cat([inception_3a_relu_1x1_out,inception_3a_relu_3x3_out,inception_3a_relu_double_3x3_2_out ,inception_3a_relu_pool_proj_out], 1)\n",
        "        inception_3b_1x1_out = self.inception_3b_1x1(inception_3a_output_out)\n",
        "        inception_3b_1x1_bn_out = self.inception_3b_1x1_bn(inception_3b_1x1_out)\n",
        "        inception_3b_relu_1x1_out = self.inception_3b_relu_1x1(inception_3b_1x1_bn_out)\n",
        "        inception_3b_3x3_reduce_out = self.inception_3b_3x3_reduce(inception_3a_output_out)\n",
        "        inception_3b_3x3_reduce_bn_out = self.inception_3b_3x3_reduce_bn(inception_3b_3x3_reduce_out)\n",
        "        inception_3b_relu_3x3_reduce_out = self.inception_3b_relu_3x3_reduce(inception_3b_3x3_reduce_bn_out)\n",
        "        inception_3b_3x3_out = self.inception_3b_3x3(inception_3b_relu_3x3_reduce_out)\n",
        "        inception_3b_3x3_bn_out = self.inception_3b_3x3_bn(inception_3b_3x3_out)\n",
        "        inception_3b_relu_3x3_out = self.inception_3b_relu_3x3(inception_3b_3x3_bn_out)\n",
        "        inception_3b_double_3x3_reduce_out = self.inception_3b_double_3x3_reduce(inception_3a_output_out)\n",
        "        inception_3b_double_3x3_reduce_bn_out = self.inception_3b_double_3x3_reduce_bn(inception_3b_double_3x3_reduce_out)\n",
        "        inception_3b_relu_double_3x3_reduce_out = self.inception_3b_relu_double_3x3_reduce(inception_3b_double_3x3_reduce_bn_out)\n",
        "        inception_3b_double_3x3_1_out = self.inception_3b_double_3x3_1(inception_3b_relu_double_3x3_reduce_out)\n",
        "        inception_3b_double_3x3_1_bn_out = self.inception_3b_double_3x3_1_bn(inception_3b_double_3x3_1_out)\n",
        "        inception_3b_relu_double_3x3_1_out = self.inception_3b_relu_double_3x3_1(inception_3b_double_3x3_1_bn_out)\n",
        "        inception_3b_double_3x3_2_out = self.inception_3b_double_3x3_2(inception_3b_relu_double_3x3_1_out)\n",
        "        inception_3b_double_3x3_2_bn_out = self.inception_3b_double_3x3_2_bn(inception_3b_double_3x3_2_out)\n",
        "        inception_3b_relu_double_3x3_2_out = self.inception_3b_relu_double_3x3_2(inception_3b_double_3x3_2_bn_out)\n",
        "        inception_3b_pool_out = self.inception_3b_pool(inception_3a_output_out)\n",
        "        inception_3b_pool_proj_out = self.inception_3b_pool_proj(inception_3b_pool_out)\n",
        "        inception_3b_pool_proj_bn_out = self.inception_3b_pool_proj_bn(inception_3b_pool_proj_out)\n",
        "        inception_3b_relu_pool_proj_out = self.inception_3b_relu_pool_proj(inception_3b_pool_proj_bn_out)\n",
        "        inception_3b_output_out = torch.cat([inception_3b_relu_1x1_out,inception_3b_relu_3x3_out,inception_3b_relu_double_3x3_2_out,inception_3b_relu_pool_proj_out], 1)\n",
        "        inception_3c_3x3_reduce_out = self.inception_3c_3x3_reduce(inception_3b_output_out)\n",
        "        inception_3c_3x3_reduce_bn_out = self.inception_3c_3x3_reduce_bn(inception_3c_3x3_reduce_out)\n",
        "        inception_3c_relu_3x3_reduce_out = self.inception_3c_relu_3x3_reduce(inception_3c_3x3_reduce_bn_out)\n",
        "        inception_3c_3x3_out = self.inception_3c_3x3(inception_3c_relu_3x3_reduce_out)\n",
        "        inception_3c_3x3_bn_out = self.inception_3c_3x3_bn(inception_3c_3x3_out)\n",
        "        inception_3c_relu_3x3_out = self.inception_3c_relu_3x3(inception_3c_3x3_bn_out)\n",
        "        inception_3c_double_3x3_reduce_out = self.inception_3c_double_3x3_reduce(inception_3b_output_out)\n",
        "        inception_3c_double_3x3_reduce_bn_out = self.inception_3c_double_3x3_reduce_bn(inception_3c_double_3x3_reduce_out)\n",
        "        inception_3c_relu_double_3x3_reduce_out = self.inception_3c_relu_double_3x3_reduce(inception_3c_double_3x3_reduce_bn_out)\n",
        "        inception_3c_double_3x3_1_out = self.inception_3c_double_3x3_1(inception_3c_relu_double_3x3_reduce_out)\n",
        "        inception_3c_double_3x3_1_bn_out = self.inception_3c_double_3x3_1_bn(inception_3c_double_3x3_1_out)\n",
        "        inception_3c_relu_double_3x3_1_out = self.inception_3c_relu_double_3x3_1(inception_3c_double_3x3_1_bn_out)\n",
        "        inception_3c_double_3x3_2_out = self.inception_3c_double_3x3_2(inception_3c_relu_double_3x3_1_out)\n",
        "        inception_3c_double_3x3_2_bn_out = self.inception_3c_double_3x3_2_bn(inception_3c_double_3x3_2_out)\n",
        "        inception_3c_relu_double_3x3_2_out = self.inception_3c_relu_double_3x3_2(inception_3c_double_3x3_2_bn_out)\n",
        "        inception_3c_pool_out = self.inception_3c_pool(inception_3b_output_out)\n",
        "        inception_3c_output_out = torch.cat([inception_3c_relu_3x3_out,inception_3c_relu_double_3x3_2_out,inception_3c_pool_out], 1)\n",
        "        inception_4a_1x1_out = self.inception_4a_1x1(inception_3c_output_out)\n",
        "        inception_4a_1x1_bn_out = self.inception_4a_1x1_bn(inception_4a_1x1_out)\n",
        "        inception_4a_relu_1x1_out = self.inception_4a_relu_1x1(inception_4a_1x1_bn_out)\n",
        "        inception_4a_3x3_reduce_out = self.inception_4a_3x3_reduce(inception_3c_output_out)\n",
        "        inception_4a_3x3_reduce_bn_out = self.inception_4a_3x3_reduce_bn(inception_4a_3x3_reduce_out)\n",
        "        inception_4a_relu_3x3_reduce_out = self.inception_4a_relu_3x3_reduce(inception_4a_3x3_reduce_bn_out)\n",
        "        inception_4a_3x3_out = self.inception_4a_3x3(inception_4a_relu_3x3_reduce_out)\n",
        "        inception_4a_3x3_bn_out = self.inception_4a_3x3_bn(inception_4a_3x3_out)\n",
        "        inception_4a_relu_3x3_out = self.inception_4a_relu_3x3(inception_4a_3x3_bn_out)\n",
        "        inception_4a_double_3x3_reduce_out = self.inception_4a_double_3x3_reduce(inception_3c_output_out)\n",
        "        inception_4a_double_3x3_reduce_bn_out = self.inception_4a_double_3x3_reduce_bn(inception_4a_double_3x3_reduce_out)\n",
        "        inception_4a_relu_double_3x3_reduce_out = self.inception_4a_relu_double_3x3_reduce(inception_4a_double_3x3_reduce_bn_out)\n",
        "        inception_4a_double_3x3_1_out = self.inception_4a_double_3x3_1(inception_4a_relu_double_3x3_reduce_out)\n",
        "        inception_4a_double_3x3_1_bn_out = self.inception_4a_double_3x3_1_bn(inception_4a_double_3x3_1_out)\n",
        "        inception_4a_relu_double_3x3_1_out = self.inception_4a_relu_double_3x3_1(inception_4a_double_3x3_1_bn_out)\n",
        "        inception_4a_double_3x3_2_out = self.inception_4a_double_3x3_2(inception_4a_relu_double_3x3_1_out)\n",
        "        inception_4a_double_3x3_2_bn_out = self.inception_4a_double_3x3_2_bn(inception_4a_double_3x3_2_out)\n",
        "        inception_4a_relu_double_3x3_2_out = self.inception_4a_relu_double_3x3_2(inception_4a_double_3x3_2_bn_out)\n",
        "        inception_4a_pool_out = self.inception_4a_pool(inception_3c_output_out)\n",
        "        inception_4a_pool_proj_out = self.inception_4a_pool_proj(inception_4a_pool_out)\n",
        "        inception_4a_pool_proj_bn_out = self.inception_4a_pool_proj_bn(inception_4a_pool_proj_out)\n",
        "        inception_4a_relu_pool_proj_out = self.inception_4a_relu_pool_proj(inception_4a_pool_proj_bn_out)\n",
        "        inception_4a_output_out = torch.cat([inception_4a_relu_1x1_out,inception_4a_relu_3x3_out,inception_4a_relu_double_3x3_2_out,inception_4a_relu_pool_proj_out], 1)\n",
        "        inception_4b_1x1_out = self.inception_4b_1x1(inception_4a_output_out)\n",
        "        inception_4b_1x1_bn_out = self.inception_4b_1x1_bn(inception_4b_1x1_out)\n",
        "        inception_4b_relu_1x1_out = self.inception_4b_relu_1x1(inception_4b_1x1_bn_out)\n",
        "        inception_4b_3x3_reduce_out = self.inception_4b_3x3_reduce(inception_4a_output_out)\n",
        "        inception_4b_3x3_reduce_bn_out = self.inception_4b_3x3_reduce_bn(inception_4b_3x3_reduce_out)\n",
        "        inception_4b_relu_3x3_reduce_out = self.inception_4b_relu_3x3_reduce(inception_4b_3x3_reduce_bn_out)\n",
        "        inception_4b_3x3_out = self.inception_4b_3x3(inception_4b_relu_3x3_reduce_out)\n",
        "        inception_4b_3x3_bn_out = self.inception_4b_3x3_bn(inception_4b_3x3_out)\n",
        "        inception_4b_relu_3x3_out = self.inception_4b_relu_3x3(inception_4b_3x3_bn_out)\n",
        "        inception_4b_double_3x3_reduce_out = self.inception_4b_double_3x3_reduce(inception_4a_output_out)\n",
        "        inception_4b_double_3x3_reduce_bn_out = self.inception_4b_double_3x3_reduce_bn(inception_4b_double_3x3_reduce_out)\n",
        "        inception_4b_relu_double_3x3_reduce_out = self.inception_4b_relu_double_3x3_reduce(inception_4b_double_3x3_reduce_bn_out)\n",
        "        inception_4b_double_3x3_1_out = self.inception_4b_double_3x3_1(inception_4b_relu_double_3x3_reduce_out)\n",
        "        inception_4b_double_3x3_1_bn_out = self.inception_4b_double_3x3_1_bn(inception_4b_double_3x3_1_out)\n",
        "        inception_4b_relu_double_3x3_1_out = self.inception_4b_relu_double_3x3_1(inception_4b_double_3x3_1_bn_out)\n",
        "        inception_4b_double_3x3_2_out = self.inception_4b_double_3x3_2(inception_4b_relu_double_3x3_1_out)\n",
        "        inception_4b_double_3x3_2_bn_out = self.inception_4b_double_3x3_2_bn(inception_4b_double_3x3_2_out)\n",
        "        inception_4b_relu_double_3x3_2_out = self.inception_4b_relu_double_3x3_2(inception_4b_double_3x3_2_bn_out)\n",
        "        inception_4b_pool_out = self.inception_4b_pool(inception_4a_output_out)\n",
        "        inception_4b_pool_proj_out = self.inception_4b_pool_proj(inception_4b_pool_out)\n",
        "        inception_4b_pool_proj_bn_out = self.inception_4b_pool_proj_bn(inception_4b_pool_proj_out)\n",
        "        inception_4b_relu_pool_proj_out = self.inception_4b_relu_pool_proj(inception_4b_pool_proj_bn_out)\n",
        "        inception_4b_output_out = torch.cat([inception_4b_relu_1x1_out,inception_4b_relu_3x3_out,inception_4b_relu_double_3x3_2_out,inception_4b_relu_pool_proj_out], 1)\n",
        "        inception_4c_1x1_out = self.inception_4c_1x1(inception_4b_output_out)\n",
        "        inception_4c_1x1_bn_out = self.inception_4c_1x1_bn(inception_4c_1x1_out)\n",
        "        inception_4c_relu_1x1_out = self.inception_4c_relu_1x1(inception_4c_1x1_bn_out)\n",
        "        inception_4c_3x3_reduce_out = self.inception_4c_3x3_reduce(inception_4b_output_out)\n",
        "        inception_4c_3x3_reduce_bn_out = self.inception_4c_3x3_reduce_bn(inception_4c_3x3_reduce_out)\n",
        "        inception_4c_relu_3x3_reduce_out = self.inception_4c_relu_3x3_reduce(inception_4c_3x3_reduce_bn_out)\n",
        "        inception_4c_3x3_out = self.inception_4c_3x3(inception_4c_relu_3x3_reduce_out)\n",
        "        inception_4c_3x3_bn_out = self.inception_4c_3x3_bn(inception_4c_3x3_out)\n",
        "        inception_4c_relu_3x3_out = self.inception_4c_relu_3x3(inception_4c_3x3_bn_out)\n",
        "        inception_4c_double_3x3_reduce_out = self.inception_4c_double_3x3_reduce(inception_4b_output_out)\n",
        "        inception_4c_double_3x3_reduce_bn_out = self.inception_4c_double_3x3_reduce_bn(inception_4c_double_3x3_reduce_out)\n",
        "        inception_4c_relu_double_3x3_reduce_out = self.inception_4c_relu_double_3x3_reduce(inception_4c_double_3x3_reduce_bn_out)\n",
        "        inception_4c_double_3x3_1_out = self.inception_4c_double_3x3_1(inception_4c_relu_double_3x3_reduce_out)\n",
        "        inception_4c_double_3x3_1_bn_out = self.inception_4c_double_3x3_1_bn(inception_4c_double_3x3_1_out)\n",
        "        inception_4c_relu_double_3x3_1_out = self.inception_4c_relu_double_3x3_1(inception_4c_double_3x3_1_bn_out)\n",
        "        inception_4c_double_3x3_2_out = self.inception_4c_double_3x3_2(inception_4c_relu_double_3x3_1_out)\n",
        "        inception_4c_double_3x3_2_bn_out = self.inception_4c_double_3x3_2_bn(inception_4c_double_3x3_2_out)\n",
        "        inception_4c_relu_double_3x3_2_out = self.inception_4c_relu_double_3x3_2(inception_4c_double_3x3_2_bn_out)\n",
        "        inception_4c_pool_out = self.inception_4c_pool(inception_4b_output_out)\n",
        "        inception_4c_pool_proj_out = self.inception_4c_pool_proj(inception_4c_pool_out)\n",
        "        inception_4c_pool_proj_bn_out = self.inception_4c_pool_proj_bn(inception_4c_pool_proj_out)\n",
        "        inception_4c_relu_pool_proj_out = self.inception_4c_relu_pool_proj(inception_4c_pool_proj_bn_out)\n",
        "        inception_4c_output_out = torch.cat([inception_4c_relu_1x1_out,inception_4c_relu_3x3_out,inception_4c_relu_double_3x3_2_out,inception_4c_relu_pool_proj_out], 1)\n",
        "        inception_4d_1x1_out = self.inception_4d_1x1(inception_4c_output_out)\n",
        "        inception_4d_1x1_bn_out = self.inception_4d_1x1_bn(inception_4d_1x1_out)\n",
        "        inception_4d_relu_1x1_out = self.inception_4d_relu_1x1(inception_4d_1x1_bn_out)\n",
        "        inception_4d_3x3_reduce_out = self.inception_4d_3x3_reduce(inception_4c_output_out)\n",
        "        inception_4d_3x3_reduce_bn_out = self.inception_4d_3x3_reduce_bn(inception_4d_3x3_reduce_out)\n",
        "        inception_4d_relu_3x3_reduce_out = self.inception_4d_relu_3x3_reduce(inception_4d_3x3_reduce_bn_out)\n",
        "        inception_4d_3x3_out = self.inception_4d_3x3(inception_4d_relu_3x3_reduce_out)\n",
        "        inception_4d_3x3_bn_out = self.inception_4d_3x3_bn(inception_4d_3x3_out)\n",
        "        inception_4d_relu_3x3_out = self.inception_4d_relu_3x3(inception_4d_3x3_bn_out)\n",
        "        inception_4d_double_3x3_reduce_out = self.inception_4d_double_3x3_reduce(inception_4c_output_out)\n",
        "        inception_4d_double_3x3_reduce_bn_out = self.inception_4d_double_3x3_reduce_bn(inception_4d_double_3x3_reduce_out)\n",
        "        inception_4d_relu_double_3x3_reduce_out = self.inception_4d_relu_double_3x3_reduce(inception_4d_double_3x3_reduce_bn_out)\n",
        "        inception_4d_double_3x3_1_out = self.inception_4d_double_3x3_1(inception_4d_relu_double_3x3_reduce_out)\n",
        "        inception_4d_double_3x3_1_bn_out = self.inception_4d_double_3x3_1_bn(inception_4d_double_3x3_1_out)\n",
        "        inception_4d_relu_double_3x3_1_out = self.inception_4d_relu_double_3x3_1(inception_4d_double_3x3_1_bn_out)\n",
        "        inception_4d_double_3x3_2_out = self.inception_4d_double_3x3_2(inception_4d_relu_double_3x3_1_out)\n",
        "        inception_4d_double_3x3_2_bn_out = self.inception_4d_double_3x3_2_bn(inception_4d_double_3x3_2_out)\n",
        "        inception_4d_relu_double_3x3_2_out = self.inception_4d_relu_double_3x3_2(inception_4d_double_3x3_2_bn_out)\n",
        "        inception_4d_pool_out = self.inception_4d_pool(inception_4c_output_out)\n",
        "        inception_4d_pool_proj_out = self.inception_4d_pool_proj(inception_4d_pool_out)\n",
        "        inception_4d_pool_proj_bn_out = self.inception_4d_pool_proj_bn(inception_4d_pool_proj_out)\n",
        "        inception_4d_relu_pool_proj_out = self.inception_4d_relu_pool_proj(inception_4d_pool_proj_bn_out)\n",
        "        inception_4d_output_out = torch.cat([inception_4d_relu_1x1_out,inception_4d_relu_3x3_out,inception_4d_relu_double_3x3_2_out,inception_4d_relu_pool_proj_out], 1)\n",
        "        inception_4e_3x3_reduce_out = self.inception_4e_3x3_reduce(inception_4d_output_out)\n",
        "        inception_4e_3x3_reduce_bn_out = self.inception_4e_3x3_reduce_bn(inception_4e_3x3_reduce_out)\n",
        "        inception_4e_relu_3x3_reduce_out = self.inception_4e_relu_3x3_reduce(inception_4e_3x3_reduce_bn_out)\n",
        "        inception_4e_3x3_out = self.inception_4e_3x3(inception_4e_relu_3x3_reduce_out)\n",
        "        inception_4e_3x3_bn_out = self.inception_4e_3x3_bn(inception_4e_3x3_out)\n",
        "        inception_4e_relu_3x3_out = self.inception_4e_relu_3x3(inception_4e_3x3_bn_out)\n",
        "        inception_4e_double_3x3_reduce_out = self.inception_4e_double_3x3_reduce(inception_4d_output_out)\n",
        "        inception_4e_double_3x3_reduce_bn_out = self.inception_4e_double_3x3_reduce_bn(inception_4e_double_3x3_reduce_out)\n",
        "        inception_4e_relu_double_3x3_reduce_out = self.inception_4e_relu_double_3x3_reduce(inception_4e_double_3x3_reduce_bn_out)\n",
        "        inception_4e_double_3x3_1_out = self.inception_4e_double_3x3_1(inception_4e_relu_double_3x3_reduce_out)\n",
        "        inception_4e_double_3x3_1_bn_out = self.inception_4e_double_3x3_1_bn(inception_4e_double_3x3_1_out)\n",
        "        inception_4e_relu_double_3x3_1_out = self.inception_4e_relu_double_3x3_1(inception_4e_double_3x3_1_bn_out)\n",
        "        inception_4e_double_3x3_2_out = self.inception_4e_double_3x3_2(inception_4e_relu_double_3x3_1_out)\n",
        "        inception_4e_double_3x3_2_bn_out = self.inception_4e_double_3x3_2_bn(inception_4e_double_3x3_2_out)\n",
        "        inception_4e_relu_double_3x3_2_out = self.inception_4e_relu_double_3x3_2(inception_4e_double_3x3_2_bn_out)\n",
        "        inception_4e_pool_out = self.inception_4e_pool(inception_4d_output_out)\n",
        "        inception_4e_output_out = torch.cat([inception_4e_relu_3x3_out,inception_4e_relu_double_3x3_2_out,inception_4e_pool_out], 1)\n",
        "        inception_5a_1x1_out = self.inception_5a_1x1(inception_4e_output_out)\n",
        "        inception_5a_1x1_bn_out = self.inception_5a_1x1_bn(inception_5a_1x1_out)\n",
        "        inception_5a_relu_1x1_out = self.inception_5a_relu_1x1(inception_5a_1x1_bn_out)\n",
        "        inception_5a_3x3_reduce_out = self.inception_5a_3x3_reduce(inception_4e_output_out)\n",
        "        inception_5a_3x3_reduce_bn_out = self.inception_5a_3x3_reduce_bn(inception_5a_3x3_reduce_out)\n",
        "        inception_5a_relu_3x3_reduce_out = self.inception_5a_relu_3x3_reduce(inception_5a_3x3_reduce_bn_out)\n",
        "        inception_5a_3x3_out = self.inception_5a_3x3(inception_5a_relu_3x3_reduce_out)\n",
        "        inception_5a_3x3_bn_out = self.inception_5a_3x3_bn(inception_5a_3x3_out)\n",
        "        inception_5a_relu_3x3_out = self.inception_5a_relu_3x3(inception_5a_3x3_bn_out)\n",
        "        inception_5a_double_3x3_reduce_out = self.inception_5a_double_3x3_reduce(inception_4e_output_out)\n",
        "        inception_5a_double_3x3_reduce_bn_out = self.inception_5a_double_3x3_reduce_bn(inception_5a_double_3x3_reduce_out)\n",
        "        inception_5a_relu_double_3x3_reduce_out = self.inception_5a_relu_double_3x3_reduce(inception_5a_double_3x3_reduce_bn_out)\n",
        "        inception_5a_double_3x3_1_out = self.inception_5a_double_3x3_1(inception_5a_relu_double_3x3_reduce_out)\n",
        "        inception_5a_double_3x3_1_bn_out = self.inception_5a_double_3x3_1_bn(inception_5a_double_3x3_1_out)\n",
        "        inception_5a_relu_double_3x3_1_out = self.inception_5a_relu_double_3x3_1(inception_5a_double_3x3_1_bn_out)\n",
        "        inception_5a_double_3x3_2_out = self.inception_5a_double_3x3_2(inception_5a_relu_double_3x3_1_out)\n",
        "        inception_5a_double_3x3_2_bn_out = self.inception_5a_double_3x3_2_bn(inception_5a_double_3x3_2_out)\n",
        "        inception_5a_relu_double_3x3_2_out = self.inception_5a_relu_double_3x3_2(inception_5a_double_3x3_2_bn_out)\n",
        "        inception_5a_pool_out = self.inception_5a_pool(inception_4e_output_out)\n",
        "        inception_5a_pool_proj_out = self.inception_5a_pool_proj(inception_5a_pool_out)\n",
        "        inception_5a_pool_proj_bn_out = self.inception_5a_pool_proj_bn(inception_5a_pool_proj_out)\n",
        "        inception_5a_relu_pool_proj_out = self.inception_5a_relu_pool_proj(inception_5a_pool_proj_bn_out)\n",
        "        inception_5a_output_out = torch.cat([inception_5a_relu_1x1_out,inception_5a_relu_3x3_out,inception_5a_relu_double_3x3_2_out,inception_5a_relu_pool_proj_out], 1)\n",
        "        inception_5b_1x1_out = self.inception_5b_1x1(inception_5a_output_out)\n",
        "        inception_5b_1x1_bn_out = self.inception_5b_1x1_bn(inception_5b_1x1_out)\n",
        "        inception_5b_relu_1x1_out = self.inception_5b_relu_1x1(inception_5b_1x1_bn_out)\n",
        "        inception_5b_3x3_reduce_out = self.inception_5b_3x3_reduce(inception_5a_output_out)\n",
        "        inception_5b_3x3_reduce_bn_out = self.inception_5b_3x3_reduce_bn(inception_5b_3x3_reduce_out)\n",
        "        inception_5b_relu_3x3_reduce_out = self.inception_5b_relu_3x3_reduce(inception_5b_3x3_reduce_bn_out)\n",
        "        inception_5b_3x3_out = self.inception_5b_3x3(inception_5b_relu_3x3_reduce_out)\n",
        "        inception_5b_3x3_bn_out = self.inception_5b_3x3_bn(inception_5b_3x3_out)\n",
        "        inception_5b_relu_3x3_out = self.inception_5b_relu_3x3(inception_5b_3x3_bn_out)\n",
        "        inception_5b_double_3x3_reduce_out = self.inception_5b_double_3x3_reduce(inception_5a_output_out)\n",
        "        inception_5b_double_3x3_reduce_bn_out = self.inception_5b_double_3x3_reduce_bn(inception_5b_double_3x3_reduce_out)\n",
        "        inception_5b_relu_double_3x3_reduce_out = self.inception_5b_relu_double_3x3_reduce(inception_5b_double_3x3_reduce_bn_out)\n",
        "        inception_5b_double_3x3_1_out = self.inception_5b_double_3x3_1(inception_5b_relu_double_3x3_reduce_out)\n",
        "        inception_5b_double_3x3_1_bn_out = self.inception_5b_double_3x3_1_bn(inception_5b_double_3x3_1_out)\n",
        "        inception_5b_relu_double_3x3_1_out = self.inception_5b_relu_double_3x3_1(inception_5b_double_3x3_1_bn_out)\n",
        "        inception_5b_double_3x3_2_out = self.inception_5b_double_3x3_2(inception_5b_relu_double_3x3_1_out)\n",
        "        inception_5b_double_3x3_2_bn_out = self.inception_5b_double_3x3_2_bn(inception_5b_double_3x3_2_out)\n",
        "        inception_5b_relu_double_3x3_2_out = self.inception_5b_relu_double_3x3_2(inception_5b_double_3x3_2_bn_out)\n",
        "        inception_5b_pool_out = self.inception_5b_pool(inception_5a_output_out)\n",
        "        inception_5b_pool_proj_out = self.inception_5b_pool_proj(inception_5b_pool_out)\n",
        "        inception_5b_pool_proj_bn_out = self.inception_5b_pool_proj_bn(inception_5b_pool_proj_out)\n",
        "        inception_5b_relu_pool_proj_out = self.inception_5b_relu_pool_proj(inception_5b_pool_proj_bn_out)\n",
        "        inception_5b_output_out = torch.cat([inception_5b_relu_1x1_out,inception_5b_relu_3x3_out,inception_5b_relu_double_3x3_2_out,inception_5b_relu_pool_proj_out], 1)\n",
        "        return inception_5b_output_out\n",
        "\n",
        "    def logits(self, features):\n",
        "        adaptiveAvgPoolWidth = features.shape[2]\n",
        "        x = F.avg_pool2d(features, kernel_size=adaptiveAvgPoolWidth)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "def bninception(num_classes=1000, pretrained='imagenet'):\n",
        "    r\"\"\"BNInception model architecture from <https://arxiv.org/pdf/1502.03167.pdf>`_ paper.\n",
        "    \"\"\"\n",
        "    model = BNInception(num_classes=num_classes)\n",
        "    if pretrained is not None:\n",
        "        settings = pretrained_settings['bninception'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    model = bninception()\n",
        "\n",
        "net=bninception(num_classes=1000, pretrained='imagenet')\n",
        "print(net)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b98a83370ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbninception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfbresnet152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fbresnet152' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OisO-uPb91j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4cdd8c84f056491c89fe28bbed67280a",
            "32f46c6048dd424d8a3ef9e049431413",
            "0000af2e396542ba9e0a73ff8c2d9bba",
            "1277a4046650498bbe38a73a7b5577f4",
            "4f755fde917e4d689d92b8d2107d6108",
            "f88c1cec815b4710afa3ad5aa3a2b04d",
            "5380f08b2c7b493daa001fb01848f39f",
            "f50413bad2ff435e8f5802cdd25442a8"
          ]
        },
        "outputId": "30d311f1-dc5f-4a55-8e23-3217d4ad3c39"
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['FBResNet',\n",
        "           #'fbresnet18', 'fbresnet34', 'fbresnet50', 'fbresnet101',\n",
        "           'fbresnet152']\n",
        "\n",
        "pretrained_settings = {\n",
        "    'fbresnet152': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/fbresnet152-2e20f6b4.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 224, 224],\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [0.485, 0.456, 0.406],\n",
        "            'std': [0.229, 0.224, 0.225],\n",
        "            'num_classes': 1000\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=True)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=True)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=True)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class FBResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        # Special attributs\n",
        "        self.input_space = None\n",
        "        self.input_size = (299, 299, 3)\n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "        super(FBResNet, self).__init__()\n",
        "        # Modules\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                                bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=True),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def features(self, input):\n",
        "        x = self.conv1(input)\n",
        "        self.conv1_input = x.clone()\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "    def logits(self, features):\n",
        "        adaptiveAvgPoolWidth = features.shape[2]\n",
        "        x = F.avg_pool2d(features, kernel_size=adaptiveAvgPoolWidth)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def fbresnet18(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet34(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet50(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet101(num_classes=1000):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def fbresnet152(num_classes=1000, pretrained='imagenet'):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = FBResNet(Bottleneck, [3, 8, 36, 3], num_classes=num_classes)\n",
        "    if pretrained is not None:\n",
        "        settings = pretrained_settings['fbresnet152'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    return model\n",
        "\n",
        "net=fbresnet152(num_classes=1000, pretrained='imagenet')\n",
        "print(net)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/fbresnet152-2e20f6b4.pth\" to /root/.cache/torch/checkpoints/fbresnet152-2e20f6b4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cdd8c84f056491c89fe28bbed67280a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241799809.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "FBResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (12): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (13): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (14): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (15): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (16): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (17): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (18): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (19): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (20): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (21): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (22): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (23): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (24): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (25): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (26): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (27): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (28): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (29): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (30): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (31): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (32): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (33): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (34): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (35): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SaCsIzPcwCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from torch.autograd import Variable\n",
        "\n",
        "pretrained_settings = {\n",
        "    'nasnetalarge': {\n",
        "        'imagenet': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 331, 331], # resize 354\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [0.5, 0.5, 0.5],\n",
        "            'std': [0.5, 0.5, 0.5],\n",
        "            'num_classes': 1000\n",
        "        },\n",
        "        'imagenet+background': {\n",
        "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth',\n",
        "            'input_space': 'RGB',\n",
        "            'input_size': [3, 331, 331], # resize 354\n",
        "            'input_range': [0, 1],\n",
        "            'mean': [0.5, 0.5, 0.5],\n",
        "            'std': [0.5, 0.5, 0.5],\n",
        "            'num_classes': 1001\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "class MaxPoolPad(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MaxPoolPad, self).__init__()\n",
        "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        x = self.pool(x)\n",
        "        x = x[:, :, 1:, 1:]\n",
        "        return x\n",
        "\n",
        "\n",
        "class AvgPoolPad(nn.Module):\n",
        "\n",
        "    def __init__(self, stride=2, padding=1):\n",
        "        super(AvgPoolPad, self).__init__()\n",
        "        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        x = self.pool(x)\n",
        "        x = x[:, :, 1:, 1:]\n",
        "        return x\n",
        "\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n",
        "                                          stride=dw_stride,\n",
        "                                          padding=dw_padding,\n",
        "                                          bias=bias,\n",
        "                                          groups=in_channels)\n",
        "        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise_conv2d(x)\n",
        "        x = self.pointwise_conv2d(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BranchSeparables(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
        "        super(BranchSeparables, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n",
        "        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
        "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(x)\n",
        "        x = self.separable_1(x)\n",
        "        x = self.bn_sep_1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.separable_2(x)\n",
        "        x = self.bn_sep_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BranchSeparablesStem(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n",
        "        super(BranchSeparablesStem, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n",
        "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(x)\n",
        "        x = self.separable_1(x)\n",
        "        x = self.bn_sep_1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.separable_2(x)\n",
        "        x = self.bn_sep_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BranchSeparablesReduction(BranchSeparables):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n",
        "        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n",
        "        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(x)\n",
        "        x = self.padding(x)\n",
        "        x = self.separable_1(x)\n",
        "        x = x[:, :, 1:, 1:].contiguous()\n",
        "        x = self.bn_sep_1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.separable_2(x)\n",
        "        x = self.bn_sep_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CellStem0(nn.Module):\n",
        "    def __init__(self, stem_filters, num_filters=42):\n",
        "        super(CellStem0, self).__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.stem_filters = stem_filters\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2)\n",
        "        self.comb_iter_0_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.comb_iter_1_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
        "        self.comb_iter_2_right = BranchSeparablesStem(self.stem_filters, self.num_filters, 5, 2, 2, bias=False)\n",
        "\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, bias=False)\n",
        "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv_1x1(x)\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n",
        "        x_comb_iter_2_right = self.comb_iter_2_right(x)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
        "\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
        "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
        "        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
        "\n",
        "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class CellStem1(nn.Module):\n",
        "\n",
        "    def __init__(self, stem_filters, num_filters):\n",
        "        super(CellStem1, self).__init__()\n",
        "        self.num_filters = num_filters\n",
        "        self.stem_filters = stem_filters\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(2*self.num_filters, self.num_filters, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.path_1 = nn.Sequential()\n",
        "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
        "        self.path_1.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
        "        self.path_2 = nn.ModuleList()\n",
        "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
        "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
        "        self.path_2.add_module('conv', nn.Conv2d(self.stem_filters, self.num_filters//2, 1, stride=1, bias=False))\n",
        "\n",
        "        self.final_path_bn = nn.BatchNorm2d(self.num_filters, eps=0.001, momentum=0.1, affine=True)\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, bias=False)\n",
        "        self.comb_iter_0_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.comb_iter_1_right = BranchSeparables(self.num_filters, self.num_filters, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
        "        self.comb_iter_2_right = BranchSeparables(self.num_filters, self.num_filters, 5, 2, 2, bias=False)\n",
        "\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparables(self.num_filters, self.num_filters, 3, 1, 1, bias=False)\n",
        "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x_conv0, x_stem_0):\n",
        "        x_left = self.conv_1x1(x_stem_0)\n",
        "\n",
        "        x_relu = self.relu(x_conv0)\n",
        "        # path 1\n",
        "        x_path1 = self.path_1(x_relu)\n",
        "        # path 2\n",
        "        x_path2 = self.path_2.pad(x_relu)\n",
        "        x_path2 = x_path2[:, :, 1:, 1:]\n",
        "        x_path2 = self.path_2.avgpool(x_path2)\n",
        "        x_path2 = self.path_2.conv(x_path2)\n",
        "        # final path\n",
        "        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n",
        "        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
        "\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
        "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
        "        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
        "\n",
        "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class FirstCell(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
        "        super(FirstCell, self).__init__()\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.path_1 = nn.Sequential()\n",
        "        self.path_1.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
        "        self.path_1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
        "        self.path_2 = nn.ModuleList()\n",
        "        self.path_2.add_module('pad', nn.ZeroPad2d((0, 1, 0, 1)))\n",
        "        self.path_2.add_module('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n",
        "        self.path_2.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
        "\n",
        "        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
        "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
        "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, x_prev):\n",
        "        x_relu = self.relu(x_prev)\n",
        "        # path 1\n",
        "        x_path1 = self.path_1(x_relu)\n",
        "        # path 2\n",
        "        x_path2 = self.path_2.pad(x_relu)\n",
        "        x_path2 = x_path2[:, :, 1:, 1:]\n",
        "        x_path2 = self.path_2.avgpool(x_path2)\n",
        "        x_path2 = self.path_2.conv(x_path2)\n",
        "        # final path\n",
        "        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
        "\n",
        "        x_right = self.conv_1x1(x)\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
        "\n",
        "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
        "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
        "\n",
        "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class NormalCell(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
        "        super(NormalCell, self).__init__()\n",
        "        self.conv_prev_1x1 = nn.Sequential()\n",
        "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
        "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n",
        "        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n",
        "        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, x_prev):\n",
        "        x_left = self.conv_prev_1x1(x_prev)\n",
        "        x_right = self.conv_1x1(x)\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_left\n",
        "\n",
        "        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n",
        "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_right\n",
        "\n",
        "        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class ReductionCell0(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
        "        super(ReductionCell0, self).__init__()\n",
        "        self.conv_prev_1x1 = nn.Sequential()\n",
        "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
        "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
        "        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = MaxPoolPad()\n",
        "        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = AvgPoolPad()\n",
        "        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
        "\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "        self.comb_iter_4_right = MaxPoolPad()\n",
        "\n",
        "    def forward(self, x, x_prev):\n",
        "        x_left = self.conv_prev_1x1(x_prev)\n",
        "        x_right = self.conv_1x1(x)\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
        "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
        "\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
        "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
        "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
        "\n",
        "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class ReductionCell1(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n",
        "        super(ReductionCell1, self).__init__()\n",
        "        self.conv_prev_1x1 = nn.Sequential()\n",
        "        self.conv_prev_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_prev_1x1.add_module('conv', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n",
        "        self.conv_prev_1x1.add_module('bn', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.conv_1x1 = nn.Sequential()\n",
        "        self.conv_1x1.add_module('relu', nn.ReLU())\n",
        "        self.conv_1x1.add_module('conv', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n",
        "        self.conv_1x1.add_module('bn', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
        "        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n",
        "\n",
        "        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
        "        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n",
        "\n",
        "        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n",
        "\n",
        "        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n",
        "        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x, x_prev):\n",
        "        x_left = self.conv_prev_1x1(x_prev)\n",
        "        x_right = self.conv_1x1(x)\n",
        "\n",
        "        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n",
        "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
        "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
        "\n",
        "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
        "        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n",
        "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
        "\n",
        "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
        "        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n",
        "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
        "\n",
        "        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n",
        "        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n",
        "\n",
        "        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n",
        "        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
        "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
        "\n",
        "        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class NASNetALarge(nn.Module):\n",
        "    \"\"\"NASNetALarge (6 @ 4032) \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=1001, stem_filters=96, penultimate_filters=4032, filters_multiplier=2):\n",
        "        super(NASNetALarge, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.stem_filters = stem_filters\n",
        "        self.penultimate_filters = penultimate_filters\n",
        "        self.filters_multiplier = filters_multiplier\n",
        "\n",
        "        filters = self.penultimate_filters // 24\n",
        "        # 24 is default value for the architecture\n",
        "\n",
        "        self.conv0 = nn.Sequential()\n",
        "        self.conv0.add_module('conv', nn.Conv2d(in_channels=3, out_channels=self.stem_filters, kernel_size=3, padding=0, stride=2,\n",
        "                                                bias=False))\n",
        "        self.conv0.add_module('bn', nn.BatchNorm2d(self.stem_filters, eps=0.001, momentum=0.1, affine=True))\n",
        "\n",
        "        self.cell_stem_0 = CellStem0(self.stem_filters, num_filters=filters // (filters_multiplier ** 2))\n",
        "        self.cell_stem_1 = CellStem1(self.stem_filters, num_filters=filters // filters_multiplier)\n",
        "\n",
        "        self.cell_0 = FirstCell(in_channels_left=filters, out_channels_left=filters//2,\n",
        "                                in_channels_right=2*filters, out_channels_right=filters)\n",
        "        self.cell_1 = NormalCell(in_channels_left=2*filters, out_channels_left=filters,\n",
        "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
        "        self.cell_2 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
        "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
        "        self.cell_3 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
        "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
        "        self.cell_4 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
        "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
        "        self.cell_5 = NormalCell(in_channels_left=6*filters, out_channels_left=filters,\n",
        "                                 in_channels_right=6*filters, out_channels_right=filters)\n",
        "\n",
        "        self.reduction_cell_0 = ReductionCell0(in_channels_left=6*filters, out_channels_left=2*filters,\n",
        "                                               in_channels_right=6*filters, out_channels_right=2*filters)\n",
        "\n",
        "        self.cell_6 = FirstCell(in_channels_left=6*filters, out_channels_left=filters,\n",
        "                                in_channels_right=8*filters, out_channels_right=2*filters)\n",
        "        self.cell_7 = NormalCell(in_channels_left=8*filters, out_channels_left=2*filters,\n",
        "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
        "        self.cell_8 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
        "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
        "        self.cell_9 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
        "                                 in_channels_right=12*filters, out_channels_right=2*filters)\n",
        "        self.cell_10 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
        "                                  in_channels_right=12*filters, out_channels_right=2*filters)\n",
        "        self.cell_11 = NormalCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
        "                                  in_channels_right=12*filters, out_channels_right=2*filters)\n",
        "\n",
        "        self.reduction_cell_1 = ReductionCell1(in_channels_left=12*filters, out_channels_left=4*filters,\n",
        "                                               in_channels_right=12*filters, out_channels_right=4*filters)\n",
        "\n",
        "        self.cell_12 = FirstCell(in_channels_left=12*filters, out_channels_left=2*filters,\n",
        "                                 in_channels_right=16*filters, out_channels_right=4*filters)\n",
        "        self.cell_13 = NormalCell(in_channels_left=16*filters, out_channels_left=4*filters,\n",
        "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
        "        self.cell_14 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
        "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
        "        self.cell_15 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
        "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
        "        self.cell_16 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
        "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
        "        self.cell_17 = NormalCell(in_channels_left=24*filters, out_channels_left=4*filters,\n",
        "                                  in_channels_right=24*filters, out_channels_right=4*filters)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.avg_pool = nn.AvgPool2d(11, stride=1, padding=0)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.last_linear = nn.Linear(24*filters, self.num_classes)\n",
        "\n",
        "    def features(self, input):\n",
        "        x_conv0 = self.conv0(input)\n",
        "        x_stem_0 = self.cell_stem_0(x_conv0)\n",
        "        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n",
        "\n",
        "        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n",
        "        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n",
        "        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n",
        "        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n",
        "        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n",
        "        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n",
        "\n",
        "        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n",
        "\n",
        "        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n",
        "        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n",
        "        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n",
        "        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n",
        "        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n",
        "        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n",
        "\n",
        "        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n",
        "\n",
        "        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n",
        "        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n",
        "        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n",
        "        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n",
        "        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n",
        "        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n",
        "        return x_cell_17\n",
        "\n",
        "    def logits(self, features):\n",
        "        x = self.relu(features)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def nasnetalarge(num_classes=1001, pretrained='imagenet'):\n",
        "    r\"\"\"NASNetALarge model architecture from the\n",
        "    `\"NASNet\" <https://arxiv.org/abs/1707.07012>`_ paper.\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['nasnetalarge'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        # both 'imagenet'&'imagenet+background' are loaded from same parameters\n",
        "        model = NASNetALarge(num_classes=1001)\n",
        "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
        "\n",
        "        if pretrained == 'imagenet':\n",
        "            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n",
        "            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n",
        "            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n",
        "            model.last_linear = new_last_linear\n",
        "\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "    else:\n",
        "        model = NASNetALarge(num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model = NASNetALarge()\n",
        "    input = Variable(torch.randn(2, 3, 331, 331))\n",
        "\n",
        "    output = model(input)\n",
        "    print(output.size())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}